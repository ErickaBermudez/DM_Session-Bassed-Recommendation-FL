{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9c5e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 0.18.0\n",
      "numpy 1.21.5\n",
      "torch 1.11.0+cu102\n",
      "torchvision 0.12.0+cu102\n",
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "import flwr as fl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "# DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d5340",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd96fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./jd_computer_final1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb26aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1429297"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80d8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844cd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = []\n",
    "session = df['Session_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a6a68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      6, ..., 999995, 999997, 999999])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "578dd60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 999999 // NUM_CLIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2a9432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488656"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b774dff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3344"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84a5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = [0 for i in range(NUM_CLIENTS + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57816e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_CLIENTS + 1):\n",
    "    if i == 0:\n",
    "        df2[i] = df[df['Session_ID'].between((i * partition_size) - 1, ((i+1) * partition_size), inclusive='right')]\n",
    "    else:\n",
    "        df2[i] = df[df['Session_ID'].between((i * partition_size), ((i+1) * partition_size), inclusive='right')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce97d6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c01ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_val = partition_size // 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10086240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6206c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainclient = [0 for i in range(NUM_CLIENTS + 1)]\n",
    "valclient = [0 for i in range(NUM_CLIENTS + 1)]\n",
    "for i in range(NUM_CLIENTS + 1):\n",
    "    trainclient[i] = df2[i][df2[i]['Session_ID'] < (((i+1) * partition_size) - len_val)]\n",
    "    valclient[i] = df2[i][df2[i]['Session_ID'] >= (((i+1) * partition_size) - len_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac54201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, path, sep=',', session_key='Session_ID', item_key='category', time_key='Seq', n_sample=-1, itemmap=None, itemstamp=None, time_sort=True):\n",
    "        # Read csv\n",
    "        #self.df = pd.read_csv(path, sep=sep, dtype={session_key: int, item_key: int, time_key: float})\n",
    "        self.df = path\n",
    "        self.session_key = session_key\n",
    "        self.item_key = item_key\n",
    "        self.time_key = time_key\n",
    "        self.time_sort = time_sort\n",
    "        if n_sample > 0:\n",
    "            self.df = self.df[:n_sample]\n",
    "\n",
    "        # Add colummn item index to data\n",
    "        self.add_item_indices(itemmap=itemmap)\n",
    "        \"\"\"\n",
    "        Sort the df by time, and then by session ID. That is, df is sorted by session ID and\n",
    "        clicks within a session are next to each other, where the clicks within a session are time-ordered.\n",
    "        \"\"\"\n",
    "        self.df.sort_values([session_key, time_key], inplace=True)\n",
    "        self.click_offsets = self.get_click_offset()\n",
    "        self.session_idx_arr = self.order_session_idx()\n",
    "\n",
    "    def add_item_indices(self, itemmap=None):\n",
    "        \"\"\"\n",
    "        Add item index column named \"item_idx\" to the df\n",
    "        Args:\n",
    "            itemmap (pd.DataFrame): mapping between the item Ids and indices\n",
    "        \"\"\"\n",
    "        if itemmap is None:\n",
    "            item_ids = self.df[self.item_key].unique()  # type is numpy.ndarray\n",
    "            item2idx = pd.Series(data=np.arange(len(item_ids)),\n",
    "                                 index=item_ids)\n",
    "            # Build itemmap is a DataFrame that have 2 columns (self.item_key, 'item_idx)\n",
    "            itemmap = pd.DataFrame({self.item_key: item_ids,\n",
    "                                   'item_idx': item2idx[item_ids].values})\n",
    "        self.itemmap = itemmap\n",
    "        self.df = pd.merge(self.df, self.itemmap, on=self.item_key, how='inner')\n",
    "\n",
    "    def get_click_offset(self):\n",
    "        \"\"\"\n",
    "        self.df[self.session_key] return a set of session_key\n",
    "        self.df[self.session_key].nunique() return the size of session_key set (int)\n",
    "        self.df.groupby(self.session_key).size() return the size of each session_id\n",
    "        self.df.groupby(self.session_key).size().cumsum() retunn cumulative sum\n",
    "        \"\"\"\n",
    "        offsets = np.zeros(self.df[self.session_key].nunique() + 1, dtype=np.int32)\n",
    "        offsets[1:] = self.df.groupby(self.session_key).size().cumsum()\n",
    "        return offsets\n",
    "\n",
    "    def order_session_idx(self):\n",
    "        if self.time_sort:\n",
    "            sessions_start_time = self.df.groupby(self.session_key)[self.time_key].min().values\n",
    "            session_idx_arr = np.argsort(sessions_start_time)\n",
    "        else:\n",
    "            session_idx_arr = np.arange(self.df[self.session_key].nunique())\n",
    "        return session_idx_arr\n",
    "\n",
    "    @property\n",
    "    def items(self):\n",
    "        return self.itemmap[self.item_key].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a1eab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dataset, batch_size=50):\n",
    "        \"\"\"\n",
    "        A class for creating session-parallel mini-batches.\n",
    "\n",
    "        Args:\n",
    "             dataset (SessionDataset): the session dataset to generate the batches from\n",
    "             batch_size (int): size of the batch\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n",
    "\n",
    "        Yields:\n",
    "            input (B,): torch.FloatTensor. Item indices that will be encoded as one-hot vectors later.\n",
    "            target (B,): a Variable that stores the target item indices\n",
    "            masks: Numpy array indicating the positions of the sessions to be terminated\n",
    "        \"\"\"\n",
    "        # initializations\n",
    "        df = self.dataset.df\n",
    "        click_offsets = self.dataset.click_offsets\n",
    "        session_idx_arr = self.dataset.session_idx_arr\n",
    "\n",
    "        iters = np.arange(self.batch_size)\n",
    "        maxiter = iters.max()\n",
    "        start = click_offsets[session_idx_arr[iters]]\n",
    "        end = click_offsets[session_idx_arr[iters] + 1]\n",
    "        mask = []  # indicator for the sessions to be terminated\n",
    "        finished = False\n",
    "\n",
    "        while not finished:\n",
    "            minlen = (end - start).min()\n",
    "            # Item indices(for embedding) for clicks where the first sessions start\n",
    "            idx_target = df.item_idx.values[start]\n",
    "\n",
    "            for i in range(minlen - 1):\n",
    "                # Build inputs & targets\n",
    "                idx_input = idx_target\n",
    "                idx_target = df.item_idx.values[start + i + 1]\n",
    "                input = torch.LongTensor(idx_input)\n",
    "                target = torch.LongTensor(idx_target)\n",
    "                yield input, target, mask\n",
    "\n",
    "            # click indices where a particular session meets second-to-last element\n",
    "            start = start + (minlen - 1)\n",
    "            # see if how many sessions should terminate\n",
    "            mask = np.arange(len(iters))[(end - start) <= 1]\n",
    "            for idx in mask:\n",
    "                maxiter += 1\n",
    "                if maxiter >= len(click_offsets) - 1:\n",
    "                    finished = True\n",
    "                    break\n",
    "                # update the next starting/ending point\n",
    "                iters[idx] = maxiter\n",
    "                start[idx] = click_offsets[session_idx_arr[maxiter]]\n",
    "                end[idx] = click_offsets[session_idx_arr[maxiter] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d63a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [0 for i in range(NUM_CLIENTS + 1)]\n",
    "valid_data = [0 for i in range(NUM_CLIENTS + 1)]\n",
    "for i in range(NUM_CLIENTS + 1):\n",
    "    train_data[i] = Dataset(trainclient[i])\n",
    "    valid_data[i] = Dataset(valclient[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5bc037",
   "metadata": {},
   "source": [
    "## Single Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbf38624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TOP1_max(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TOP1_max, self).__init__()\n",
    "\n",
    "    def forward(self, logit):\n",
    "        logit_softmax = F.softmax(logit, dim=1)\n",
    "        diff = -(logit.diag().view(-1, 1).expand_as(logit) - logit)\n",
    "        loss = torch.mean(logit_softmax * (torch.sigmoid(diff) + torch.sigmoid(logit ** 2)))\n",
    "        return loss\n",
    "    \n",
    "class TOP1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TOP1Loss, self).__init__()\n",
    "    def forward(self, logit):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logit (BxB): Variable that stores the logits for the items in the mini-batch\n",
    "                         The first dimension corresponds to the batches, and the second\n",
    "                         dimension corresponds to sampled number of items to evaluate\n",
    "        \"\"\"\n",
    "        diff = -(logit.diag().view(-1, 1).expand_as(logit) - logit)\n",
    "        loss = torch.sigmoid(diff).mean() + torch.sigmoid(logit ** 2).mean()\n",
    "        return loss    \n",
    "    \n",
    "class LossFunction(nn.Module):\n",
    "    def __init__(self, loss_type='TOP1', use_cuda=False):\n",
    "        \"\"\" An abstract loss function that can supports custom loss functions compatible with PyTorch.\"\"\"\n",
    "        super(LossFunction, self).__init__()\n",
    "        self.loss_type = loss_type\n",
    "        self.use_cuda = use_cuda\n",
    "        if loss_type == 'TOP1-max':\n",
    "            self._loss_fn = TOP1_max()\n",
    "        elif loss_type == 'TOP1':\n",
    "            self._loss_fn = TOP1Loss()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, logit):\n",
    "        return self._loss_fn(logit) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49a91947",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = LossFunction('TOP1-max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c236866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU4REC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, final_act='tanh',\n",
    "                 dropout_hidden=.5, dropout_input=0, batch_size=50, embedding_dim=-1, use_cuda=False):\n",
    "        super(GRU4REC, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_hidden = dropout_hidden\n",
    "        self.dropout_input = dropout_input\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.use_cuda = use_cuda\n",
    "        self.device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "        self.onehot_buffer = self.init_emb()\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.create_final_activation(final_act)\n",
    "        if self.embedding_dim != -1:\n",
    "            self.look_up = nn.Embedding(input_size, self.embedding_dim)\n",
    "            self.gru = nn.GRU(self.embedding_dim, self.hidden_size, self.num_layers, dropout=self.dropout_hidden)\n",
    "        else:\n",
    "            self.gru = nn.GRU(self.input_size, self.hidden_size, self.num_layers, dropout=self.dropout_hidden)\n",
    "        self = self.to(self.device)\n",
    "\n",
    "    def create_final_activation(self, final_act):\n",
    "        if final_act == 'tanh':\n",
    "            self.final_activation = nn.Tanh()\n",
    "        elif final_act == 'relu':\n",
    "            self.final_activation = nn.ReLU()\n",
    "        elif final_act == 'softmax':\n",
    "            self.final_activation = nn.Softmax()\n",
    "        elif final_act == 'softmax_logit':\n",
    "            self.final_activation = nn.LogSoftmax()\n",
    "        elif final_act.startswith('elu-'):\n",
    "            self.final_activation = nn.ELU(alpha=float(final_act.split('-')[1]))\n",
    "        elif final_act.startswith('leaky-'):\n",
    "            self.final_activation = nn.LeakyReLU(negative_slope=float(final_act.split('-')[1]))\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        '''\n",
    "        Args:\n",
    "            input (B,): a batch of item indices from a session-parallel mini-batch.\n",
    "            target (B,): torch.LongTensor of next item indices from a session-parallel mini-batch.\n",
    "\n",
    "        Returns:\n",
    "            logit (B,C): Variable that stores the logits for the next items in the session-parallel mini-batch\n",
    "            hidden: GRU hidden state\n",
    "        '''\n",
    "\n",
    "        if self.embedding_dim == -1:\n",
    "            embedded = self.onehot_encode(input)\n",
    "            if self.training and self.dropout_input > 0: embedded = self.embedding_dropout(embedded)\n",
    "            embedded = embedded.unsqueeze(0)\n",
    "        else:\n",
    "            embedded = input.unsqueeze(0)\n",
    "            embedded = self.look_up(embedded)\n",
    "\n",
    "        output, hidden = self.gru(embedded, hidden) #(num_layer, B, H)\n",
    "        output = output.view(-1, output.size(-1))  #(B,H)\n",
    "        logit = self.final_activation(self.h2o(output))\n",
    "\n",
    "        return logit, hidden\n",
    "\n",
    "    def init_emb(self):\n",
    "        '''\n",
    "        Initialize the one_hot embedding buffer, which will be used for producing the one-hot embeddings efficiently\n",
    "        '''\n",
    "        onehot_buffer = torch.FloatTensor(self.batch_size, self.output_size)\n",
    "        onehot_buffer = onehot_buffer.to(self.device)\n",
    "        return onehot_buffer\n",
    "\n",
    "    def onehot_encode(self, input):\n",
    "        \"\"\"\n",
    "        Returns a one-hot vector corresponding to the input\n",
    "        Args:\n",
    "            input (B,): torch.LongTensor of item indices\n",
    "            buffer (B,output_size): buffer that stores the one-hot vector\n",
    "        Returns:\n",
    "            one_hot (B,C): torch.FloatTensor of one-hot vectors\n",
    "        \"\"\"\n",
    "        self.onehot_buffer.zero_()\n",
    "        index = input.view(-1, 1)\n",
    "        one_hot = self.onehot_buffer.scatter_(1, index, 1)\n",
    "        return one_hot\n",
    "\n",
    "    def embedding_dropout(self, input):\n",
    "        p_drop = torch.Tensor(input.size(0), 1).fill_(1 - self.dropout_input)\n",
    "        mask = torch.bernoulli(p_drop).expand_as(input) / (1 - self.dropout_input)\n",
    "        mask = mask.to(self.device)\n",
    "        input = input * mask\n",
    "        return input\n",
    "\n",
    "    def init_hidden(self):\n",
    "        '''\n",
    "        Initialize the hidden state of the GRU\n",
    "        '''\n",
    "        try:\n",
    "            h0 = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        except:\n",
    "            self.device = 'cpu'\n",
    "            h0 = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        return h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c878bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(train_data[105].items)\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "output_size = input_size\n",
    "batch_size = 64\n",
    "dropout_input = 0\n",
    "dropout_hidden = 0.5\n",
    "embedding_dim = -1\n",
    "final_act = 'tanh'\n",
    "loss_type = 'TOP1-max'\n",
    "optimizer_type = 'Adagrad'\n",
    "lr = 0.05\n",
    "weight_decay = 0\n",
    "momentum = 0\n",
    "eps = 1e-6\n",
    "n_epochs = 5\n",
    "time_sort = False\n",
    "sigma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2365005d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c31fb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "18493cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f687815e4b0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use random seed defined\n",
    "np.random.seed(22)\n",
    "torch.manual_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b933d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e5932317",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = LossFunction(loss_type=loss_type, use_cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "97a387ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU4REC(input_size, hidden_size, output_size, final_act=final_act,\n",
    "                            num_layers=num_layers, use_cuda=cuda, batch_size=batch_size,\n",
    "                            dropout_input=dropout_input, dropout_hidden=dropout_hidden, embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a77d7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model):\n",
    "    global sigma\n",
    "    if sigma is not None:\n",
    "        for p in model.parameters():\n",
    "            if sigma != -1 and sigma != -2:\n",
    "                sigma = sigma\n",
    "                p.data.uniform_(-sigma, sigma)\n",
    "            elif len(list(p.size())) > 1:\n",
    "                sigma = np.sqrt(6.0 / (p.size(0) + p.size(1)))\n",
    "                if sigma == -1:\n",
    "                    p.data.uniform_(-sigma, sigma)\n",
    "                else:\n",
    "                    p.data.uniform_(0, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ccde8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b0dfd8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, optimizer_type='Adagrad', lr=.05,\n",
    "                 momentum=0, weight_decay=0, eps=1e-6):\n",
    "        '''\n",
    "        An abstract optimizer class for handling various kinds of optimizers.\n",
    "        You can specify the optimizer type and related parameters as you want.\n",
    "        Usage is exactly the same as an instance of torch.optim\n",
    "\n",
    "        Args:\n",
    "            params: torch.nn.Parameter. The NN parameters to optimize\n",
    "            optimizer_type: type of the optimizer to use\n",
    "            lr: learning rate\n",
    "            momentum: momentum, if needed\n",
    "            weight_decay: weight decay, if needed. Equivalent to L2 regulariztion.\n",
    "            eps: eps parameter, if needed.\n",
    "        '''\n",
    "        if optimizer_type == 'RMSProp':\n",
    "            self.optimizer = optim.RMSprop(params, lr=lr, eps=eps, weight_decay=weight_decay, momentum=momentum)\n",
    "        elif optimizer_type == 'Adagrad':\n",
    "            self.optimizer = optim.Adagrad(params, lr=lr, weight_decay=weight_decay)\n",
    "        elif optimizer_type == 'Adadelta':\n",
    "            self.optimizer = optim.Adadelta(params, lr=lr, eps=eps, weight_decay=weight_decay)\n",
    "        elif optimizer_type == 'Adam':\n",
    "            self.optimizer = optim.Adam(params, lr=lr, eps=eps, weight_decay=weight_decay)\n",
    "        elif optimizer_type == 'SparseAdam':\n",
    "            self.optimizer = optim.SparseAdam(params, lr=lr, eps=eps)\n",
    "        elif optimizer_type == 'SGD':\n",
    "            self.optimizer = optim.SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6617488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(model.parameters(), optimizer_type=optimizer_type, lr=lr, weight_decay=weight_decay, momentum=momentum, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "af3388c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(indices, targets): #recall --> wether next item in session is within top K=20 recommended items or not\n",
    "    \"\"\"\n",
    "    Calculates the recall score for the given predictions and targets\n",
    "    Args:\n",
    "        indices (Bxk): torch.LongTensor. top-k indices predicted by the model.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "    Returns:\n",
    "        recall (float): the recall score\n",
    "    \"\"\"\n",
    "    targets = targets.view(-1, 1).expand_as(indices)\n",
    "    hits = (targets == indices).nonzero()\n",
    "    if len(hits) == 0:\n",
    "        return 0\n",
    "    n_hits = (targets == indices).nonzero()[:, :-1].size(0)\n",
    "    recall = float(n_hits) / targets.size(0)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "88853eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mrr(indices, targets): #Mean Receiprocal Rank --> Average of rank of next item in the session.\n",
    "    \"\"\"\n",
    "    Calculates the MRR score for the given predictions and targets\n",
    "    Args:\n",
    "        indices (Bxk): torch.LongTensor. top-k indices predicted by the model.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "    Returns:\n",
    "        mrr (float): the mrr score\n",
    "    \"\"\"\n",
    "    tmp = targets.view(-1, 1)\n",
    "    targets = tmp.expand_as(indices)\n",
    "    hits = (targets == indices).nonzero()\n",
    "    ranks = hits[:, -1] + 1\n",
    "    ranks = ranks.float()\n",
    "    rranks = torch.reciprocal(ranks)\n",
    "    mrr = torch.sum(rranks).data / targets.size(0)\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "718acdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(indices, targets, k=20):\n",
    "    \"\"\"\n",
    "    Evaluates the model using Recall@K, MRR@K scores.\n",
    "\n",
    "    Args:\n",
    "        logits (B,C): torch.LongTensor. The predicted logit for the next items.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "\n",
    "    Returns:\n",
    "        recall (float): the recall score\n",
    "        mrr (float): the mrr score\n",
    "    \"\"\"\n",
    "    _, indices = torch.topk(indices, k, -1)\n",
    "    recall = get_recall(indices, targets)\n",
    "    mrr = get_mrr(indices, targets)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "664ce881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(object):\n",
    "    def __init__(self, model, loss_func, use_cuda, k=5):\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.topk = k\n",
    "        self.device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "        #self.device = torch.device('cpu')\n",
    "\n",
    "    def eval(self, eval_data, batch_size):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        recalls = []\n",
    "        mrrs = []\n",
    "        dataloader = DataLoader(eval_data, batch_size)\n",
    "        with torch.no_grad():\n",
    "            hidden = self.model.init_hidden()\n",
    "            for ii, (input, target, mask) in enumerate(dataloader):\n",
    "            #for input, target, mask in dataloader:\n",
    "                input = input.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                logit, hidden = self.model(input, hidden)\n",
    "                logit_sampled = logit[:, target.view(-1)]\n",
    "                loss = self.loss_func(logit_sampled)\n",
    "                recall, mrr = evaluate(logit, target, k=self.topk)\n",
    "\n",
    "                # torch.Tensor.item() to get a Python number from a tensor containing a single value\n",
    "                losses.append(loss.item())\n",
    "                recalls.append(recall)\n",
    "                mrrs.append(mrr.cpu())\n",
    "        mean_losses = np.mean(losses)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_mrr = np.mean(mrrs)\n",
    "        #mean_mrr = 0\n",
    "\n",
    "        return mean_losses, mean_recall, mean_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "68c81de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, train_data, eval_data, optim, use_cuda, loss_func, batch_size):\n",
    "        self.model = model\n",
    "        self.train_data = train_data\n",
    "        self.eval_data = eval_data\n",
    "        self.optim = optim\n",
    "        self.loss_func = loss_func\n",
    "        self.evaluation = Evaluation(self.model, self.loss_func, use_cuda, k = 5)\n",
    "        self.device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "        #self.device = torch.device('cpu')\n",
    "        self.batch_size = batch_size\n",
    "        #self.args = args\n",
    "\n",
    "    def train(self, start_epoch, end_epoch, start_time=None):\n",
    "        if start_time is None:\n",
    "            self.start_time = time.time()\n",
    "        else:\n",
    "            self.start_time = start_time\n",
    "\n",
    "        for epoch in range(start_epoch, end_epoch + 1):\n",
    "            st = time.time()\n",
    "            print('Start Epoch #', epoch)\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            loss, recall, mrr = self.evaluation.eval(self.eval_data, self.batch_size)\n",
    "\n",
    "\n",
    "            print(\"Epoch: {}, train loss: {:.4f}, loss: {:.4f}, recall: {:.4f}, mrr: {:.4f}, time: {}\".format(epoch, train_loss, loss, recall, mrr, time.time() - st))\n",
    "            checkpoint = {\n",
    "                'model': self.model,\n",
    "                'epoch': epoch,\n",
    "                'optim': self.optim,\n",
    "                'loss': loss,\n",
    "                'recall': recall,\n",
    "                'mrr': mrr\n",
    "            }\n",
    "            #model_name = os.path.join('checkpoint', \"model_{0:05d}.pt\".format(epoch))\n",
    "            #torch.save(checkpoint, model_name)\n",
    "            #print(\"Save model as %s\" % model_name)\n",
    "\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "\n",
    "        def reset_hidden(hidden, mask):\n",
    "            \"\"\"Helper function that resets hidden state when some sessions terminate\"\"\"\n",
    "            if len(mask) != 0:\n",
    "                hidden[:, mask, :] = 0\n",
    "            return hidden\n",
    "\n",
    "        hidden = self.model.init_hidden()\n",
    "        dataloader = DataLoader(self.train_data, self.batch_size)\n",
    "        #for ii,(data,label) in tqdm(enumerate(train_dataloader),total=len(train_data)):\n",
    "        for ii, (input, target, mask) in enumerate(dataloader):\n",
    "            input = input.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            self.optim.zero_grad()\n",
    "            hidden = reset_hidden(hidden, mask).detach()\n",
    "            logit, hidden = self.model(input, hidden)\n",
    "            # output sampling\n",
    "            logit_sampled = logit[:, target.view(-1)]\n",
    "            loss = self.loss_func(logit_sampled)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "        mean_losses = np.mean(losses)\n",
    "        return mean_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0d67c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, train_data=train_data[105], eval_data=valid_data[105], optim=optimizer, use_cuda=cuda, loss_func=loss_function, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4b0276bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### START TRAINING....\n",
      "Start Epoch # 0\n",
      "Epoch: 0, train loss: 0.0144, loss: 0.0148, recall: 0.5547, mrr: 0.5068, time: 0.07386970520019531\n",
      "Start Epoch # 1\n",
      "Epoch: 1, train loss: 0.0140, loss: 0.0148, recall: 0.5547, mrr: 0.5013, time: 0.06340599060058594\n",
      "Start Epoch # 2\n",
      "Epoch: 2, train loss: 0.0139, loss: 0.0148, recall: 0.5547, mrr: 0.4928, time: 0.05922079086303711\n",
      "Start Epoch # 3\n",
      "Epoch: 3, train loss: 0.0139, loss: 0.0148, recall: 0.5469, mrr: 0.4918, time: 0.06041860580444336\n",
      "Start Epoch # 4\n",
      "Epoch: 4, train loss: 0.0139, loss: 0.0148, recall: 0.5469, mrr: 0.4910, time: 0.05916309356689453\n"
     ]
    }
   ],
   "source": [
    "print('#### START TRAINING....')\n",
    "trainer.train(0, n_epochs - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6575e",
   "metadata": {},
   "source": [
    "## FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ec3b00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f687815e4b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use random seed defined\n",
    "np.random.seed(22)\n",
    "torch.manual_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c127dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, train_data, eval_data, optim, use_cuda, loss_func, batch_size, clientID = 0):\n",
    "        self.model = model\n",
    "        self.train_data = train_data\n",
    "        self.eval_data = eval_data\n",
    "        self.optim = optim\n",
    "        self.loss_func = loss_func\n",
    "        self.evaluation = Evaluation(self.model, self.loss_func, use_cuda, k = 5)\n",
    "        self.device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "        #self.device = torch.device('cpu')\n",
    "        self.batch_size = batch_size\n",
    "        self.clientID = clientID\n",
    "        #self.args = args\n",
    "\n",
    "    def train(self, start_epoch, end_epoch, start_time=None):\n",
    "        if start_time is None:\n",
    "            self.start_time = time.time()\n",
    "        else:\n",
    "            self.start_time = start_time\n",
    "\n",
    "        for epoch in range(start_epoch, end_epoch + 1):\n",
    "            st = time.time()\n",
    "            print('Start Epoch #', self.clientID)\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            loss, recall, mrr = self.evaluation.eval(self.eval_data, self.batch_size)\n",
    "\n",
    "\n",
    "            print(\"client: {}, train loss: {:.4f}, loss: {:.4f}, recall: {:.4f}, mrr: {:.4f}, time: {}\".format(self.clientID, train_loss, loss, recall, mrr, time.time() - st))\n",
    "            checkpoint = {\n",
    "                'model': self.model,\n",
    "                'epoch': epoch,\n",
    "                'optim': self.optim,\n",
    "                'loss': loss,\n",
    "                'recall': recall,\n",
    "                'mrr': mrr\n",
    "            }\n",
    "            #model_name = os.path.join('checkpoint', \"model_{0:05d}.pt\".format(epoch))\n",
    "            #torch.save(checkpoint, model_name)\n",
    "            #print(\"Save model as %s\" % model_name)\n",
    "\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "\n",
    "        def reset_hidden(hidden, mask):\n",
    "            \"\"\"Helper function that resets hidden state when some sessions terminate\"\"\"\n",
    "            if len(mask) != 0:\n",
    "                hidden[:, mask, :] = 0\n",
    "            return hidden\n",
    "\n",
    "        hidden = self.model.init_hidden()\n",
    "        dataloader = DataLoader(self.train_data, self.batch_size)\n",
    "        #for ii,(data,label) in tqdm(enumerate(train_dataloader),total=len(train_data)):\n",
    "        for ii, (input, target, mask) in enumerate(dataloader):\n",
    "            input = input.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            self.optim.zero_grad()\n",
    "            hidden = reset_hidden(hidden, mask).detach()\n",
    "            logit, hidden = self.model(input, hidden)\n",
    "            # output sampling\n",
    "            logit_sampled = logit[:, target.view(-1)]\n",
    "            loss = self.loss_func(logit_sampled)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "        mean_losses = np.mean(losses)\n",
    "        return mean_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cee9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcd5d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader, clientID = 0):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.clientID = clientID\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        trainer = Trainer(model, train_data=self.trainloader, eval_data=self.valloader, optim=optimizer, use_cuda=False, loss_func=loss_function, batch_size=batch_size, clientID=self.clientID)\n",
    "        trainer.train(0, 0)\n",
    "        #print(len(self.trainloader.df))\n",
    "        return get_parameters(self.net), len(self.trainloader.df), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        evaluation = Evaluation(self.net, loss_function, use_cuda= False, k = 5)\n",
    "        loss, recall, mrr = evaluation.eval(self.valloader, 64)\n",
    "        #loss, accuracy = test(self.net, self.valloader)\n",
    "        #print (\"print: \", recall)\n",
    "        return float(loss), len(self.valloader.df), {\"accuracy\": float(recall)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba8e8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    model = GRU4REC(87, hidden_size, 87, final_act=final_act,\n",
    "                            num_layers=num_layers, use_cuda=False, batch_size=batch_size,\n",
    "                            dropout_input=dropout_input, dropout_hidden=dropout_hidden, embedding_dim=embedding_dim).to(DEVICE)\n",
    "    \n",
    "    init_model(model)\n",
    "\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = train_data[int(cid)]\n",
    "    valloader = valid_data[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(model, trainloader, valloader, int(cid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94242b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-06-17 12:42:50,284 | app.py:147 | Ray initialized with resources: {'object_store_memory': 4760811110.0, 'memory': 9521622222.0, 'GPU': 1.0, 'node:220.67.127.72': 1.0, 'accelerator_type:G': 1.0, 'CPU': 16.0}\n",
      "INFO flower 2022-06-17 12:42:50,285 | app.py:156 | Starting Flower simulation running: {'num_rounds': 5}\n",
      "INFO flower 2022-06-17 12:42:50,286 | server.py:128 | Initializing global parameters\n",
      "INFO flower 2022-06-17 12:42:50,286 | server.py:327 | Requesting initial parameters from one random client\n",
      "INFO flower 2022-06-17 12:42:51,131 | server.py:330 | Received initial parameters from one random client\n",
      "INFO flower 2022-06-17 12:42:51,132 | server.py:130 | Evaluating initial parameters\n",
      "INFO flower 2022-06-17 12:42:51,132 | server.py:143 | FL starting\n",
      "DEBUG flower 2022-06-17 12:42:51,133 | server.py:269 | fit_round: strategy sampled 300 clients (out of 300)\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=318485)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=318485)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 297, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.6217, time: 4.1579508781433105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 104\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 102\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 272\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 24\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 85\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 230\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 97\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 41\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 113, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.6077, time: 0.15400290489196777\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 104, train loss: 0.0143, loss: 0.0147, recall: 0.5781, mrr: 0.4836, time: 0.16904211044311523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 273, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5653, time: 0.20922112464904785\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 102, train loss: 0.0144, loss: 0.0145, recall: 0.6615, mrr: 0.6044, time: 0.22640585899353027\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 272, train loss: 0.0143, loss: 0.0143, recall: 0.6667, mrr: 0.6201, time: 0.19410419464111328\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 24, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.5940, time: 0.1509106159210205\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 285, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6250, time: 0.17308998107910156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 85, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.7047, time: 0.15874481201171875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 230, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5440, time: 0.16537714004516602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 145, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6725, time: 0.16225218772888184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 97, train loss: 0.0144, loss: 0.0144, recall: 0.6510, mrr: 0.6369, time: 0.17146611213684082\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 259, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6214, time: 0.17520999908447266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 41, train loss: 0.0143, loss: 0.0146, recall: 0.7656, mrr: 0.7190, time: 0.1621534824371338\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 112, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6375, time: 0.19364213943481445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 111, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6393, time: 0.17194151878356934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 2096 MiB, 31 objects, write throughput 24 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 257\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 38\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 50\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 257, train loss: 0.0142, loss: 0.0144, recall: 0.7344, mrr: 0.5729, time: 0.08571434020996094\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 143\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 106\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 38, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6398, time: 0.07843470573425293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 240\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 5, train loss: 0.0144, loss: 0.0144, recall: 0.6797, mrr: 0.6184, time: 0.0866248607635498\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 174\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 50, train loss: 0.0142, loss: 0.0147, recall: 0.6094, mrr: 0.5639, time: 0.23303818702697754\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 143, train loss: 0.0144, loss: 0.0150, recall: 0.5312, mrr: 0.4944, time: 0.23725199699401855\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 106, train loss: 0.0142, loss: 0.0149, recall: 0.5625, mrr: 0.4875, time: 0.22381281852722168\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 240, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.6281, time: 0.24448204040527344\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 174, train loss: 0.0142, loss: 0.0146, recall: 0.6016, mrr: 0.5602, time: 0.2449657917022705\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 156, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6450, time: 0.22056961059570312\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 54\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 54, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5662, time: 0.07554507255554199\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 182\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 182, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5159, time: 0.06228160858154297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 45\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 8\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 117, train loss: 0.0143, loss: 0.0147, recall: 0.6484, mrr: 0.5910, time: 0.09763860702514648\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 219, train loss: 0.0142, loss: 0.0148, recall: 0.6406, mrr: 0.5796, time: 0.0609285831451416\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 8, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6038, time: 0.1555931568145752\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 298\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 271\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 140\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 298, train loss: 0.0142, loss: 0.0144, recall: 0.7083, mrr: 0.5721, time: 0.06337571144104004\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 271, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5854, time: 0.06022334098815918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 19\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 19, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5641, time: 0.06642508506774902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 34\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 98\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 139\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 246, train loss: 0.0143, loss: 0.0146, recall: 0.7109, mrr: 0.5932, time: 0.06237959861755371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 29\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 56\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 34, train loss: 0.0144, loss: 0.0145, recall: 0.6406, mrr: 0.5938, time: 1.030261516571045\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 160\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 29, train loss: 0.0145, loss: 0.0146, recall: 0.5781, mrr: 0.5310, time: 0.2486131191253662\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 56, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6589, time: 0.1899547576904297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 140, train loss: 0.0142, loss: 0.0144, recall: 0.6354, mrr: 0.5954, time: 1.8212006092071533\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 210\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 209, train loss: 0.0144, loss: 0.0144, recall: 0.6953, mrr: 0.6797, time: 0.12836432456970215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 160, train loss: 0.0143, loss: 0.0146, recall: 0.6641, mrr: 0.6146, time: 0.12218570709228516\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 215, train loss: 0.0144, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.14362263679504395\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 268\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 45, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5794, time: 2.2435600757598877\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 268, train loss: 0.0143, loss: 0.0146, recall: 0.6172, mrr: 0.5504, time: 0.06767487525939941\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 42\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 98, train loss: 0.0144, loss: 0.0146, recall: 0.6172, mrr: 0.5344, time: 1.3684675693511963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 210, train loss: 0.0142, loss: 0.0147, recall: 0.5417, mrr: 0.5115, time: 0.32604026794433594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 42, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.6263, time: 0.07589912414550781\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 139, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5710, time: 1.3455111980438232\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 132\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 183\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 229\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 10, train loss: 0.0142, loss: 0.0142, recall: 0.7344, mrr: 0.6068, time: 1.221186876296997\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 183, train loss: 0.0144, loss: 0.0149, recall: 0.5781, mrr: 0.4992, time: 0.5762145519256592\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 295\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 100\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 163\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 15\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 132, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6432, time: 1.2496087551116943\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 295, train loss: 0.0143, loss: 0.0145, recall: 0.6510, mrr: 0.5953, time: 0.0915062427520752\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 63\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 134\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 15, train loss: 0.0142, loss: 0.0145, recall: 0.6641, mrr: 0.5732, time: 0.11592578887939453\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 163, train loss: 0.0143, loss: 0.0147, recall: 0.6667, mrr: 0.4780, time: 0.22201275825500488\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 86\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 100, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6320, time: 0.43065381050109863\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 280\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 229, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5677, time: 0.518561601638794\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 66\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 248\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 134, train loss: 0.0143, loss: 0.0145, recall: 0.6354, mrr: 0.5526, time: 0.3696415424346924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 280, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6083, time: 0.09647631645202637\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 245\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 248, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6302, time: 0.07728147506713867\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 86, train loss: 0.0143, loss: 0.0146, recall: 0.5990, mrr: 0.5689, time: 0.36409831047058105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 63, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6448, time: 0.5944948196411133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 245, train loss: 0.0143, loss: 0.0143, recall: 0.6484, mrr: 0.6020, time: 0.07438993453979492\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 74\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 66, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5624, time: 0.33408427238464355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 74, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5390, time: 0.22105836868286133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 84\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 43\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 43, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6523, time: 0.059334516525268555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 84, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5408, time: 0.4382154941558838\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 3, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5861, time: 0.2512962818145752\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 58\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 58, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6246, time: 0.21901535987854004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4189 MiB, 50 objects, write throughput 36 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 8258 MiB, 85 objects, write throughput 33 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 21\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 21, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6754, time: 20.188416242599487\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 92\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 12\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 122\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 151\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 239\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 92, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6057, time: 0.0869591236114502\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 12, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6660, time: 0.06515026092529297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 195, train loss: 0.0144, loss: 0.0145, recall: 0.7656, mrr: 0.7161, time: 0.061858177185058594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 101\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 122, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6359, time: 0.07389688491821289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 177\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 124\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 151, train loss: 0.0142, loss: 0.0144, recall: 0.6953, mrr: 0.6646, time: 0.07978963851928711\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 239, train loss: 0.0143, loss: 0.0139, recall: 0.8281, mrr: 0.7766, time: 0.11933159828186035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 101, train loss: 0.0142, loss: 0.0147, recall: 0.6328, mrr: 0.5452, time: 0.13011813163757324\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 207, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6630, time: 0.11298108100891113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 1, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.5926, time: 0.11542201042175293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 177, train loss: 0.0144, loss: 0.0145, recall: 0.6797, mrr: 0.6344, time: 0.10698509216308594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 124, train loss: 0.0143, loss: 0.0144, recall: 0.7266, mrr: 0.6259, time: 0.1196441650390625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 171\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 171, train loss: 0.0144, loss: 0.0144, recall: 0.6979, mrr: 0.6311, time: 0.05977272987365723\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 170\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 170, train loss: 0.0143, loss: 0.0146, recall: 0.6094, mrr: 0.5098, time: 0.06479048728942871\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 191, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6223, time: 0.06741213798522949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 109\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 109, train loss: 0.0144, loss: 0.0146, recall: 0.5898, mrr: 0.5479, time: 0.09179258346557617\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 251\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 251, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6435, time: 0.0625157356262207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 37\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 278\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 91\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 198\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 130\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 157\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 37, train loss: 0.0144, loss: 0.0147, recall: 0.6133, mrr: 0.5169, time: 0.0786430835723877\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 278, train loss: 0.0144, loss: 0.0146, recall: 0.5781, mrr: 0.5431, time: 0.0792996883392334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 91, train loss: 0.0143, loss: 0.0147, recall: 0.6615, mrr: 0.5559, time: 0.08794593811035156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 198, train loss: 0.0144, loss: 0.0143, recall: 0.6875, mrr: 0.6510, time: 0.07364702224731445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 130, train loss: 0.0143, loss: 0.0142, recall: 0.6953, mrr: 0.6673, time: 0.06573677062988281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 157, train loss: 0.0143, loss: 0.0144, recall: 0.6406, mrr: 0.6043, time: 0.10752725601196289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 40\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 40, train loss: 0.0142, loss: 0.0143, recall: 0.7656, mrr: 0.6987, time: 0.057804107666015625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 263\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 263, train loss: 0.0143, loss: 0.0147, recall: 0.6094, mrr: 0.5726, time: 0.05700516700744629\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 231\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 141\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 224\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 99\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 146\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 232\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 23\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 141, train loss: 0.0143, loss: 0.0142, recall: 0.7109, mrr: 0.6385, time: 0.11178874969482422\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 142\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 220\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 224, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.4901, time: 0.11706733703613281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 99, train loss: 0.0141, loss: 0.0142, recall: 0.6797, mrr: 0.6686, time: 0.09198832511901855\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 47\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 0, train loss: 0.0139, loss: 0.0152, recall: 0.5469, mrr: 0.3775, time: 0.15434932708740234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 232, train loss: 0.0144, loss: 0.0150, recall: 0.5781, mrr: 0.4168, time: 0.14589190483093262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 23, train loss: 0.0143, loss: 0.0144, recall: 0.6250, mrr: 0.5845, time: 0.10973978042602539\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 231, train loss: 0.0143, loss: 0.0147, recall: 0.5885, mrr: 0.4687, time: 0.13269901275634766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 142, train loss: 0.0144, loss: 0.0144, recall: 0.7031, mrr: 0.6676, time: 0.13455986976623535\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 220, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6339, time: 0.12372040748596191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 146, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.5919, time: 0.15198063850402832\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 238, train loss: 0.0143, loss: 0.0144, recall: 0.6927, mrr: 0.6056, time: 0.14295434951782227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 47, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.6680, time: 0.14313650131225586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 129, train loss: 0.0142, loss: 0.0142, recall: 0.7734, mrr: 0.7216, time: 0.13012218475341797\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 68\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 68, train loss: 0.0141, loss: 0.0145, recall: 0.6250, mrr: 0.5677, time: 0.060054779052734375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 181\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 153\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 150\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 76\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 4\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 161\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 28\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 60\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 270\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 161, train loss: 0.0142, loss: 0.0149, recall: 0.4844, mrr: 0.4410, time: 0.7555739879608154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 181, train loss: 0.0142, loss: 0.0146, recall: 0.6719, mrr: 0.6237, time: 0.7685682773590088\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 254, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.5905, time: 0.829627513885498\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 153, train loss: 0.0143, loss: 0.0146, recall: 0.7188, mrr: 0.6615, time: 0.8506159782409668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 150, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6303, time: 0.7810003757476807\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 76, train loss: 0.0144, loss: 0.0147, recall: 0.6146, mrr: 0.5184, time: 0.815169095993042\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 4, train loss: 0.0143, loss: 0.0143, recall: 0.6953, mrr: 0.6305, time: 0.839867115020752\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 154\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 28, train loss: 0.0143, loss: 0.0143, recall: 0.7344, mrr: 0.7188, time: 0.8184010982513428\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 60, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5029, time: 0.8502194881439209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 270, train loss: 0.0143, loss: 0.0142, recall: 0.7031, mrr: 0.6734, time: 0.8340115547180176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 154, train loss: 0.0143, loss: 0.0147, recall: 0.5469, mrr: 0.5172, time: 0.07408571243286133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 16428 MiB, 282 objects, write throughput 43 MiB/s.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2022-06-17 12:49:18,617 E 318403 318403] (raylet) worker_pool.cc:518: Some workers of the worker process(319584) have not registered within the timeout. The process is still alive, probably it's hanging during start.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2022-06-17 12:49:18,620 E 318403 318403] (raylet) worker_pool.cc:518: Some workers of the worker process(319585) have not registered within the timeout. The process is still alive, probably it's hanging during start.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 127\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 179\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 184, train loss: 0.0143, loss: 0.0145, recall: 0.7266, mrr: 0.6857, time: 0.07916450500488281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 127, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.06346297264099121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 179, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.6276, time: 0.05352282524108887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 136\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 136, train loss: 0.0143, loss: 0.0146, recall: 0.5469, mrr: 0.5071, time: 0.06372761726379395\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 213\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 213, train loss: 0.0144, loss: 0.0148, recall: 0.5781, mrr: 0.4879, time: 0.062410831451416016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 221\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 228\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 11\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 194\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 18\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 119\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 265\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 87\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 221, train loss: 0.0143, loss: 0.0144, recall: 0.7135, mrr: 0.6486, time: 0.11230993270874023\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 294\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 165\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 18, train loss: 0.0143, loss: 0.0146, recall: 0.6302, mrr: 0.5913, time: 0.08121514320373535\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 203, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.5908, time: 0.12915992736816406\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 265, train loss: 0.0144, loss: 0.0147, recall: 0.5729, mrr: 0.5403, time: 0.12963008880615234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 87, train loss: 0.0143, loss: 0.0144, recall: 0.6797, mrr: 0.6105, time: 0.126051664352417\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 294, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.5938, time: 0.1273205280303955\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 228, train loss: 0.0143, loss: 0.0146, recall: 0.5781, mrr: 0.5052, time: 0.12950587272644043\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 11, train loss: 0.0145, loss: 0.0146, recall: 0.5703, mrr: 0.5253, time: 0.13137078285217285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 165, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6354, time: 0.0736398696899414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 194, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.5712, time: 0.12798380851745605\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 119, train loss: 0.0142, loss: 0.0144, recall: 0.7656, mrr: 0.7500, time: 0.12200188636779785\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 252\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 252, train loss: 0.0144, loss: 0.0142, recall: 0.6797, mrr: 0.6452, time: 0.07993030548095703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 83\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 83, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4795, time: 0.0660405158996582\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 26\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 26, train loss: 0.0143, loss: 0.0144, recall: 0.5938, mrr: 0.5749, time: 0.05905461311340332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 131\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 131, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.7017, time: 0.06344389915466309\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 264\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 264, train loss: 0.0143, loss: 0.0143, recall: 0.7500, mrr: 0.6477, time: 0.08735775947570801\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 255\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 255, train loss: 0.0142, loss: 0.0146, recall: 0.6328, mrr: 0.5983, time: 0.0640251636505127\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 204\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 204, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.6099, time: 0.07902956008911133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 70\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 70, train loss: 0.0142, loss: 0.0144, recall: 0.6302, mrr: 0.5645, time: 0.08114051818847656\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 159\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 159, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.5677, time: 0.08121132850646973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 188, train loss: 0.0144, loss: 0.0149, recall: 0.5000, mrr: 0.4807, time: 0.06447172164916992\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 96\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 96, train loss: 0.0142, loss: 0.0148, recall: 0.5938, mrr: 0.5070, time: 0.06955695152282715\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 218\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 218, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6424, time: 0.06743407249450684\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 190\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 279\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 190, train loss: 0.0143, loss: 0.0149, recall: 0.5885, mrr: 0.4434, time: 0.07109832763671875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 126\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 279, train loss: 0.0141, loss: 0.0146, recall: 0.7422, mrr: 0.6980, time: 0.07637882232666016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 249\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 93\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 65\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 135\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 256\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 57\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 126, train loss: 0.0143, loss: 0.0141, recall: 0.7734, mrr: 0.6767, time: 0.09994769096374512\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 249, train loss: 0.0144, loss: 0.0148, recall: 0.5859, mrr: 0.5083, time: 0.08017373085021973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 57, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5316, time: 0.0826871395111084\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 93, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5674, time: 0.0948183536529541\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 222, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6531, time: 0.12095260620117188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 65, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6094, time: 0.10159873962402344\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 135, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5501, time: 0.09964132308959961\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 256, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.6309, time: 0.08414793014526367\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 233\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 115\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 169\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 55\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 208\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 67\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 233, train loss: 0.0144, loss: 0.0146, recall: 0.6875, mrr: 0.6099, time: 0.0861806869506836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 115, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.6428, time: 0.07957625389099121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 169, train loss: 0.0143, loss: 0.0146, recall: 0.6042, mrr: 0.5390, time: 0.07522439956665039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 55, train loss: 0.0145, loss: 0.0144, recall: 0.6719, mrr: 0.5973, time: 0.07620859146118164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 208, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5952, time: 0.07397985458374023\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 67, train loss: 0.0143, loss: 0.0141, recall: 0.7891, mrr: 0.7600, time: 0.06886744499206543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 72\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 202\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 16\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 46\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 287\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 72, train loss: 0.0143, loss: 0.0148, recall: 0.5938, mrr: 0.5529, time: 0.11527514457702637\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 202, train loss: 0.0143, loss: 0.0146, recall: 0.6953, mrr: 0.6698, time: 0.08748221397399902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 16, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5807, time: 0.10434651374816895\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 211, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.5194, time: 0.08929586410522461\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 46, train loss: 0.0142, loss: 0.0143, recall: 0.7109, mrr: 0.6641, time: 0.12163496017456055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 287, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5501, time: 0.07611393928527832\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 283\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 291, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6156, time: 0.06564021110534668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 261\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 148, train loss: 0.0144, loss: 0.0144, recall: 0.7083, mrr: 0.6253, time: 0.12184882164001465\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 283, train loss: 0.0144, loss: 0.0144, recall: 0.6172, mrr: 0.5931, time: 0.10721087455749512\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 261, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6956, time: 0.06751894950866699\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 216\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 206\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 149\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 216, train loss: 0.0143, loss: 0.0141, recall: 0.7500, mrr: 0.7083, time: 0.07360386848449707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 281, train loss: 0.0143, loss: 0.0143, recall: 0.7578, mrr: 0.7477, time: 0.08360815048217773\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 206, train loss: 0.0143, loss: 0.0145, recall: 0.6042, mrr: 0.5494, time: 0.07813501358032227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 172, train loss: 0.0143, loss: 0.0144, recall: 0.6719, mrr: 0.6219, time: 0.07106518745422363\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 225\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 225, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6697, time: 0.0804142951965332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 162\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 162, train loss: 0.0144, loss: 0.0145, recall: 0.5938, mrr: 0.5670, time: 0.07628154754638672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 149, train loss: 0.0141, loss: 0.0144, recall: 0.6953, mrr: 0.6029, time: 0.06506156921386719\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 13\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 258, train loss: 0.0144, loss: 0.0147, recall: 0.5781, mrr: 0.5617, time: 0.06160402297973633\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 32\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 13, train loss: 0.0142, loss: 0.0145, recall: 0.6562, mrr: 0.5214, time: 0.06179952621459961\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 32, train loss: 0.0143, loss: 0.0142, recall: 0.7188, mrr: 0.6708, time: 0.07755756378173828\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 247\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 247, train loss: 0.0144, loss: 0.0147, recall: 0.7031, mrr: 0.5725, time: 0.05474495887756348\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 44\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 44, train loss: 0.0142, loss: 0.0143, recall: 0.6875, mrr: 0.6382, time: 0.06169533729553223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 59\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 59, train loss: 0.0142, loss: 0.0145, recall: 0.6094, mrr: 0.6016, time: 0.05366992950439453\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 114\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 9\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 282\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 114, train loss: 0.0144, loss: 0.0147, recall: 0.6250, mrr: 0.5761, time: 0.07701706886291504\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 89\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 9, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.6510, time: 0.06871271133422852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 35\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 193\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 282, train loss: 0.0143, loss: 0.0145, recall: 0.8281, mrr: 0.6672, time: 0.06934785842895508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 88\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 121, train loss: 0.0144, loss: 0.0142, recall: 0.7500, mrr: 0.7164, time: 0.08722758293151855\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 89, train loss: 0.0143, loss: 0.0149, recall: 0.5729, mrr: 0.5129, time: 0.08920979499816895\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 35, train loss: 0.0143, loss: 0.0143, recall: 0.6823, mrr: 0.6280, time: 0.0725255012512207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 164, train loss: 0.0144, loss: 0.0146, recall: 0.5859, mrr: 0.5257, time: 0.08507943153381348\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 193, train loss: 0.0144, loss: 0.0145, recall: 0.6042, mrr: 0.5546, time: 0.09754204750061035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 88, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.5931, time: 0.09035730361938477\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 6, train loss: 0.0142, loss: 0.0143, recall: 0.6562, mrr: 0.6099, time: 0.05576896667480469\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 197\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 276\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 290\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 267\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 77\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 118\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 197, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6350, time: 0.06946134567260742\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 276, train loss: 0.0144, loss: 0.0146, recall: 0.6302, mrr: 0.5547, time: 0.0835568904876709\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 290, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5657, time: 0.07741546630859375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 267, train loss: 0.0142, loss: 0.0146, recall: 0.5833, mrr: 0.5612, time: 0.06449246406555176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 77, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.5484, time: 0.07895994186401367\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 118, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6599, time: 0.05904340744018555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 22\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 175\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 53\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 185, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.6393, time: 0.09756731986999512\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 22, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6507, time: 0.08668947219848633\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 175, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6335, time: 0.0762641429901123\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 241\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 53, train loss: 0.0144, loss: 0.0146, recall: 0.6615, mrr: 0.5601, time: 0.09391069412231445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 180\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 242, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5234, time: 0.06943798065185547\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 241, train loss: 0.0142, loss: 0.0147, recall: 0.6641, mrr: 0.5533, time: 0.08119416236877441\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 180, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.6810, time: 0.0988612174987793\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 125, train loss: 0.0144, loss: 0.0147, recall: 0.6328, mrr: 0.5630, time: 0.11013317108154297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 262, train loss: 0.0143, loss: 0.0145, recall: 0.6250, mrr: 0.6031, time: 0.11705350875854492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 17\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 73\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 80\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 94\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 64\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 253\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 253, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6102, time: 0.09323787689208984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 81\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 236\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 73, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4895, time: 0.11965322494506836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 227, train loss: 0.0143, loss: 0.0147, recall: 0.6172, mrr: 0.6003, time: 0.14535069465637207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 274\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 94, train loss: 0.0142, loss: 0.0145, recall: 0.7031, mrr: 0.6829, time: 0.09568214416503906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 31\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 64, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5874, time: 0.1267533302307129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 81, train loss: 0.0144, loss: 0.0146, recall: 0.5469, mrr: 0.5155, time: 0.10566592216491699\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 17, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.5509, time: 0.12853193283081055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 274, train loss: 0.0143, loss: 0.0147, recall: 0.5625, mrr: 0.5203, time: 0.121490478515625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 80, train loss: 0.0143, loss: 0.0146, recall: 0.6615, mrr: 0.5911, time: 0.1173858642578125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 205\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 205, train loss: 0.0142, loss: 0.0144, recall: 0.7578, mrr: 0.6117, time: 0.058320045471191406\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 31, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6615, time: 0.06747126579284668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 236, train loss: 0.0144, loss: 0.0142, recall: 0.6719, mrr: 0.6602, time: 0.12392282485961914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 168\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 168, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5689, time: 0.056627750396728516\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 39\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 39, train loss: 0.0142, loss: 0.0146, recall: 0.6250, mrr: 0.5569, time: 0.060062408447265625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 155\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 144\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 158\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 27\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 275\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 155, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5803, time: 0.10037612915039062\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 105, train loss: 0.0144, loss: 0.0147, recall: 0.5391, mrr: 0.5100, time: 0.10747051239013672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 144, train loss: 0.0144, loss: 0.0145, recall: 0.6979, mrr: 0.6681, time: 0.11815738677978516\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 158, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6100, time: 0.12065839767456055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 269\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 27, train loss: 0.0144, loss: 0.0142, recall: 0.7812, mrr: 0.6984, time: 0.08359479904174805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 137, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5836, time: 0.12470602989196777\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 275, train loss: 0.0142, loss: 0.0146, recall: 0.6562, mrr: 0.6189, time: 0.11976885795593262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 269, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6773, time: 0.06641030311584473\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 199\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 199, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.5859, time: 0.06392765045166016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 78\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 292\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 292, train loss: 0.0143, loss: 0.0148, recall: 0.5885, mrr: 0.5603, time: 0.07787537574768066\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 237\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 237, train loss: 0.0142, loss: 0.0142, recall: 0.6719, mrr: 0.6719, time: 0.06346797943115234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 296\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 69\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 284\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 186, train loss: 0.0143, loss: 0.0144, recall: 0.6992, mrr: 0.5725, time: 0.09309554100036621\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 78, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5217, time: 0.09134244918823242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 20\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 296, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.6305, time: 0.07858157157897949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 284, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.5844, time: 0.09479808807373047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 69, train loss: 0.0143, loss: 0.0143, recall: 0.6719, mrr: 0.6380, time: 0.0801541805267334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 266, train loss: 0.0142, loss: 0.0143, recall: 0.7344, mrr: 0.6526, time: 0.11870765686035156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 20, train loss: 0.0144, loss: 0.0146, recall: 0.6458, mrr: 0.5633, time: 0.1090230941772461\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 234, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6891, time: 0.11774826049804688\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 192\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 61\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 214\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 189\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 33\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 235\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 235, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5985, time: 0.0784153938293457\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 192, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6246, time: 0.08393049240112305\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 61, train loss: 0.0143, loss: 0.0141, recall: 0.7266, mrr: 0.7000, time: 0.07030797004699707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 214, train loss: 0.0144, loss: 0.0143, recall: 0.7734, mrr: 0.6698, time: 0.07200288772583008\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 189, train loss: 0.0143, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.09068155288696289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 33, train loss: 0.0144, loss: 0.0146, recall: 0.6823, mrr: 0.6515, time: 0.08881115913391113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 14\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 299\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 187\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 138\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 286\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 178\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 187, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6389, time: 0.08782839775085449\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 123\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 289, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6410, time: 0.07817339897155762\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 138, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.6432, time: 0.07223320007324219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 48\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 286, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5820, time: 0.09827971458435059\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 178, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6190, time: 0.07909035682678223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 14, train loss: 0.0143, loss: 0.0144, recall: 0.6510, mrr: 0.5925, time: 0.11878657341003418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 123, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.5559, time: 0.11269021034240723\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 152, train loss: 0.0144, loss: 0.0147, recall: 0.5859, mrr: 0.5428, time: 0.11505603790283203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 48, train loss: 0.0141, loss: 0.0144, recall: 0.6797, mrr: 0.6253, time: 0.08141875267028809\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 277, train loss: 0.0144, loss: 0.0148, recall: 0.5469, mrr: 0.4754, time: 0.12880563735961914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m   out=out, **kwargs)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m   ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 108\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 108, train loss: 0.0143, loss: 0.0145, recall: 0.6302, mrr: 0.5568, time: 0.07587337493896484\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 226\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 226, train loss: 0.0143, loss: 0.0146, recall: 0.5625, mrr: 0.5076, time: 0.05645418167114258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 110\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 110, train loss: 0.0145, loss: 0.0146, recall: 0.6172, mrr: 0.5598, time: 0.07000160217285156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 62\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 62, train loss: 0.0143, loss: 0.0145, recall: 0.6797, mrr: 0.6160, time: 0.057528018951416016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 32882 MiB, 663 objects, write throughput 48 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 200\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 200, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5898, time: 0.05363631248474121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 25\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 25, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.6276, time: 0.05237007141113281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 167\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 167, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6945, time: 0.057466745376586914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 196\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 196, train loss: 0.0144, loss: 0.0145, recall: 0.6458, mrr: 0.6007, time: 0.046274662017822266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 36\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 36, train loss: 0.0143, loss: 0.0144, recall: 0.7422, mrr: 0.6885, time: 0.057645320892333984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 173\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 173, train loss: 0.0142, loss: 0.0148, recall: 0.6562, mrr: 0.5505, time: 0.052652597427368164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 75\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 250\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 250, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5544, time: 0.05828976631164551\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 147\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 147, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6409, time: 0.055238962173461914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 212\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 212, train loss: 0.0142, loss: 0.0147, recall: 0.5938, mrr: 0.5688, time: 0.0564427375793457\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 30\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 30, train loss: 0.0143, loss: 0.0146, recall: 0.5859, mrr: 0.5716, time: 0.06526851654052734\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 201\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 201, train loss: 0.0144, loss: 0.0144, recall: 0.6562, mrr: 0.6167, time: 0.05475330352783203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 293, train loss: 0.0143, loss: 0.0144, recall: 0.6667, mrr: 0.6050, time: 0.056589603424072266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 166\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 223, train loss: 0.0144, loss: 0.0144, recall: 0.6250, mrr: 0.5803, time: 0.06366252899169922\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 166, train loss: 0.0142, loss: 0.0149, recall: 0.5547, mrr: 0.4693, time: 0.05190467834472656\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 260\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 260, train loss: 0.0143, loss: 0.0142, recall: 0.7500, mrr: 0.7233, time: 0.049985647201538086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 244\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 244, train loss: 0.0142, loss: 0.0144, recall: 0.6458, mrr: 0.5933, time: 0.05417585372924805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 243\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 243, train loss: 0.0143, loss: 0.0145, recall: 0.7109, mrr: 0.6596, time: 0.05981111526489258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 116\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 116, train loss: 0.0144, loss: 0.0148, recall: 0.5833, mrr: 0.5042, time: 0.05642533302307129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 2, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5961, time: 0.05675697326660156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 52\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 49\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 52, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6288, time: 0.05203676223754883\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 49, train loss: 0.0144, loss: 0.0142, recall: 0.6927, mrr: 0.6710, time: 0.05379009246826172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 288\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 288, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.05644845962524414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 107\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 107, train loss: 0.0143, loss: 0.0146, recall: 0.6289, mrr: 0.5212, time: 0.06448936462402344\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 95\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 95, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5624, time: 0.05086660385131836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 176, train loss: 0.0143, loss: 0.0141, recall: 0.7812, mrr: 0.7141, time: 0.04715919494628906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 79\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 79, train loss: 0.0144, loss: 0.0142, recall: 0.7031, mrr: 0.6241, time: 0.058161020278930664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 217\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 217, train loss: 0.0142, loss: 0.0147, recall: 0.6016, mrr: 0.5534, time: 0.052394866943359375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 7\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 7, train loss: 0.0144, loss: 0.0146, recall: 0.6250, mrr: 0.6038, time: 0.05576825141906738\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 128\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 128, train loss: 0.0143, loss: 0.0146, recall: 0.6328, mrr: 0.5388, time: 0.053194522857666016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 51\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 120\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 120, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5417, time: 0.04840731620788574\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 51, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5901, time: 0.060007572174072266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 71\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 71, train loss: 0.0143, loss: 0.0146, recall: 0.6354, mrr: 0.5727, time: 0.06013369560241699\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 133, train loss: 0.0143, loss: 0.0144, recall: 0.7396, mrr: 0.6594, time: 0.06891608238220215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 90\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 90, train loss: 0.0144, loss: 0.0145, recall: 0.6328, mrr: 0.5740, time: 0.05742454528808594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 12:55:42,756 | server.py:281 | fit_round received 297 results and 3 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 103\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 103, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.5661, time: 0.05695700645446777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 12:55:43,047 | server.py:215 | evaluate_round: strategy sampled 150 clients (out of 300)\n",
      "DEBUG flower 2022-06-17 12:58:01,528 | server.py:227 | evaluate_round received 149 results and 1 failures\n",
      "DEBUG flower 2022-06-17 12:58:01,539 | server.py:269 | fit_round: strategy sampled 300 clients (out of 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 296\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 29\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 40\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 85\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 290\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 228\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 270\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 288\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 99\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 17\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 216\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 286\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 299\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m   out=out, **kwargs)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m   ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 29, train loss: 0.0145, loss: 0.0146, recall: 0.5781, mrr: 0.5310, time: 0.3903508186340332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 40, train loss: 0.0142, loss: 0.0143, recall: 0.7656, mrr: 0.6987, time: 0.4155457019805908\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 85, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.7047, time: 0.4255702495574951\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 289, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6410, time: 0.4191129207611084\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 293, train loss: 0.0143, loss: 0.0144, recall: 0.6667, mrr: 0.6050, time: 0.5004582405090332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 290, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5657, time: 0.3609018325805664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 296, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.6305, time: 0.4531826972961426\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 228, train loss: 0.0143, loss: 0.0146, recall: 0.5781, mrr: 0.5052, time: 0.4621284008026123\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 270, train loss: 0.0143, loss: 0.0142, recall: 0.7031, mrr: 0.6734, time: 0.379000186920166\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 288, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.44107723236083984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 99, train loss: 0.0141, loss: 0.0142, recall: 0.6797, mrr: 0.6686, time: 0.3497281074523926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 17, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.5509, time: 0.41506266593933105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 216, train loss: 0.0143, loss: 0.0141, recall: 0.7500, mrr: 0.7083, time: 0.40602922439575195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 286, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5820, time: 0.441464900970459\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 240, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.6281, time: 0.43186354637145996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 62\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 62, train loss: 0.0143, loss: 0.0145, recall: 0.6797, mrr: 0.6160, time: 0.12302470207214355\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 232\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 244\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 153\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 250\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 218\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 83\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 134\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 280\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 243\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 122\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 146\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch #\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m  49\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 232, train loss: 0.0144, loss: 0.0150, recall: 0.5781, mrr: 0.4168, time: 0.19664978981018066\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 281, train loss: 0.0143, loss: 0.0143, recall: 0.7578, mrr: 0.7477, time: 0.17244648933410645\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 153, train loss: 0.0143, loss: 0.0146, recall: 0.7188, mrr: 0.6615, time: 0.17544126510620117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 83, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4795, time: 0.1824495792388916\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 134, train loss: 0.0143, loss: 0.0145, recall: 0.6354, mrr: 0.5526, time: 0.16941618919372559\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 243, train loss: 0.0143, loss: 0.0145, recall: 0.7109, mrr: 0.6596, time: 0.18629121780395508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 122, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6359, time: 0.17132139205932617\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 244, train loss: 0.0142, loss: 0.0144, recall: 0.6458, mrr: 0.5933, time: 0.19676780700683594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 250, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5544, time: 0.19516396522521973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 188, train loss: 0.0144, loss: 0.0149, recall: 0.5000, mrr: 0.4807, time: 0.1993391513824463\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 173\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 173, train loss: 0.0142, loss: 0.0148, recall: 0.6562, mrr: 0.5505, time: 0.08343911170959473\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 218, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6424, time: 0.1873006820678711\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 280, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6083, time: 0.18742799758911133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 49, train loss: 0.0144, loss: 0.0142, recall: 0.6927, mrr: 0.6710, time: 0.16293716430664062\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 197\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 146, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.5919, time: 0.176605224609375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 239\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 197, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6350, time: 0.07770299911499023\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 172, train loss: 0.0143, loss: 0.0144, recall: 0.6719, mrr: 0.6219, time: 0.07277536392211914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 239, train loss: 0.0143, loss: 0.0139, recall: 0.8281, mrr: 0.7766, time: 0.07589268684387207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 23\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 295\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 295, train loss: 0.0143, loss: 0.0145, recall: 0.6510, mrr: 0.5953, time: 0.0736396312713623\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 25\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 23, train loss: 0.0143, loss: 0.0144, recall: 0.6250, mrr: 0.5845, time: 0.05688929557800293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 25, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.6276, time: 0.06301522254943848\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 127\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 2, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5961, time: 0.0847783088684082\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 10, train loss: 0.0142, loss: 0.0142, recall: 0.7344, mrr: 0.6068, time: 0.07717680931091309\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 291, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6156, time: 0.0830838680267334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 282\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 282, train loss: 0.0143, loss: 0.0145, recall: 0.8281, mrr: 0.6672, time: 0.06794238090515137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 127, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.08212518692016602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 223, train loss: 0.0144, loss: 0.0144, recall: 0.6250, mrr: 0.5803, time: 0.09563851356506348\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 273, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5653, time: 0.0877077579498291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 96\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 96, train loss: 0.0142, loss: 0.0148, recall: 0.5938, mrr: 0.5070, time: 0.09509801864624023\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 54\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 24\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 177\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 229\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 54, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5662, time: 0.09599161148071289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 24, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.5940, time: 0.06236982345581055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 177, train loss: 0.0144, loss: 0.0145, recall: 0.6797, mrr: 0.6344, time: 0.05508089065551758\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 229, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5677, time: 0.07251358032226562\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 110\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 159\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 110, train loss: 0.0145, loss: 0.0146, recall: 0.6172, mrr: 0.5598, time: 0.07824969291687012\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 20\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 20, train loss: 0.0144, loss: 0.0146, recall: 0.6458, mrr: 0.5633, time: 0.07262182235717773\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 159, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.5677, time: 0.06371188163757324\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 60\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 194\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 60, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5029, time: 0.061379194259643555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 194, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.5712, time: 0.05681943893432617\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 132\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 132, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6432, time: 0.05525994300842285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 246, train loss: 0.0143, loss: 0.0146, recall: 0.7109, mrr: 0.5932, time: 0.06026792526245117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 87\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 81\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 61\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 170\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 170, train loss: 0.0143, loss: 0.0146, recall: 0.6094, mrr: 0.5098, time: 0.06359457969665527\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 89\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 161\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 87, train loss: 0.0143, loss: 0.0144, recall: 0.6797, mrr: 0.6105, time: 0.7437896728515625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 61, train loss: 0.0143, loss: 0.0141, recall: 0.7266, mrr: 0.7000, time: 0.5904390811920166\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 86, train loss: 0.0143, loss: 0.0146, recall: 0.5990, mrr: 0.5689, time: 0.5220351219177246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 215, train loss: 0.0144, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.06388711929321289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 81, train loss: 0.0144, loss: 0.0146, recall: 0.5469, mrr: 0.5155, time: 1.0210421085357666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 89, train loss: 0.0143, loss: 0.0149, recall: 0.5729, mrr: 0.5129, time: 0.5112662315368652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 161, train loss: 0.0142, loss: 0.0149, recall: 0.4844, mrr: 0.4410, time: 0.5311813354492188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 278\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 8\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 75\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 278, train loss: 0.0144, loss: 0.0146, recall: 0.5781, mrr: 0.5431, time: 0.06757616996765137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 124\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 8, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6038, time: 0.2682826519012451\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 31\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 124, train loss: 0.0143, loss: 0.0144, recall: 0.7266, mrr: 0.6259, time: 0.23235249519348145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 64\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 31, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6615, time: 1.126852035522461\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 64, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5874, time: 1.0789523124694824\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 88\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 88, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.5931, time: 0.06315231323242188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 249\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 249, train loss: 0.0144, loss: 0.0148, recall: 0.5859, mrr: 0.5083, time: 0.05970931053161621\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 51\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 51, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5901, time: 0.06242036819458008\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 165\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 19\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 201\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 72\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 165, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6354, time: 0.06796884536743164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 19, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5641, time: 0.08559346199035645\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 121, train loss: 0.0144, loss: 0.0142, recall: 0.7500, mrr: 0.7164, time: 0.07548904418945312\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 15\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 15, train loss: 0.0142, loss: 0.0145, recall: 0.6641, mrr: 0.5732, time: 0.06959772109985352\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 201, train loss: 0.0144, loss: 0.0144, recall: 0.6562, mrr: 0.6167, time: 0.07490348815917969\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 271\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 271, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5854, time: 0.06863999366760254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 72, train loss: 0.0143, loss: 0.0148, recall: 0.5938, mrr: 0.5529, time: 0.07923102378845215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 185, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.6393, time: 0.0677485466003418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 166\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 166, train loss: 0.0142, loss: 0.0149, recall: 0.5547, mrr: 0.4693, time: 0.06020498275756836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 207, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6630, time: 0.06589913368225098\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 220\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 196\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 196, train loss: 0.0144, loss: 0.0145, recall: 0.6458, mrr: 0.6007, time: 0.05388498306274414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 120\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 220, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6339, time: 0.07239055633544922\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 120, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5417, time: 0.06019115447998047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 56\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 56, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6589, time: 0.05806231498718262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 233\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 78\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 140\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 33\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 169\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 255\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 259, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6214, time: 0.0991365909576416\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 140, train loss: 0.0142, loss: 0.0144, recall: 0.6354, mrr: 0.5954, time: 0.0948479175567627\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 204\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 33, train loss: 0.0144, loss: 0.0146, recall: 0.6823, mrr: 0.6515, time: 0.10635209083557129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 233, train loss: 0.0144, loss: 0.0146, recall: 0.6875, mrr: 0.6099, time: 0.10800337791442871\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 78, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5217, time: 0.10958433151245117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 169, train loss: 0.0143, loss: 0.0146, recall: 0.6042, mrr: 0.5390, time: 0.10005021095275879\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 255, train loss: 0.0142, loss: 0.0146, recall: 0.6328, mrr: 0.5983, time: 0.08158254623413086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 184, train loss: 0.0143, loss: 0.0145, recall: 0.7266, mrr: 0.6857, time: 0.11064934730529785\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 204, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.6099, time: 0.08549809455871582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 65648 MiB, 1165 objects, write throughput 55 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 162\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 162, train loss: 0.0144, loss: 0.0145, recall: 0.5938, mrr: 0.5670, time: 0.06045866012573242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 95\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 95, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5624, time: 0.0627436637878418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 212\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 26\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 26, train loss: 0.0143, loss: 0.0144, recall: 0.5938, mrr: 0.5749, time: 0.05803418159484863\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 212, train loss: 0.0142, loss: 0.0147, recall: 0.5938, mrr: 0.5688, time: 0.06832742691040039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 283\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 283, train loss: 0.0144, loss: 0.0144, recall: 0.6172, mrr: 0.5931, time: 0.05233311653137207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 37\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 92\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 92, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6057, time: 0.0809786319732666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 199\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 130\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 37, train loss: 0.0144, loss: 0.0147, recall: 0.6133, mrr: 0.5169, time: 0.07865214347839355\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 179\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 182\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 182, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5159, time: 0.06558728218078613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 269\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 276\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 276, train loss: 0.0144, loss: 0.0146, recall: 0.6302, mrr: 0.5547, time: 0.08614063262939453\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 82\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 199, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.5859, time: 0.07358765602111816\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 130, train loss: 0.0143, loss: 0.0142, recall: 0.6953, mrr: 0.6673, time: 0.05942368507385254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 179, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.6276, time: 0.058670759201049805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 269, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6773, time: 0.07130622863769531\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 59\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 68\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 59, train loss: 0.0142, loss: 0.0145, recall: 0.6094, mrr: 0.6016, time: 0.05785059928894043\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 68, train loss: 0.0141, loss: 0.0145, recall: 0.6250, mrr: 0.5677, time: 0.06394243240356445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 275\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 219, train loss: 0.0142, loss: 0.0148, recall: 0.6406, mrr: 0.5796, time: 0.06478667259216309\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 275, train loss: 0.0142, loss: 0.0146, recall: 0.6562, mrr: 0.6189, time: 0.06802892684936523\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 192\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 192, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6246, time: 0.06907248497009277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 236\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 236, train loss: 0.0144, loss: 0.0142, recall: 0.6719, mrr: 0.6602, time: 0.06162762641906738\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 32\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 32, train loss: 0.0143, loss: 0.0142, recall: 0.7188, mrr: 0.6708, time: 0.07570433616638184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 198\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 198, train loss: 0.0144, loss: 0.0143, recall: 0.6875, mrr: 0.6510, time: 0.0627586841583252\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 126\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 126, train loss: 0.0143, loss: 0.0141, recall: 0.7734, mrr: 0.6767, time: 0.06880617141723633\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 237\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 237, train loss: 0.0142, loss: 0.0142, recall: 0.6719, mrr: 0.6719, time: 0.05352020263671875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 35\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 217\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 224\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 189\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 248\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 16\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 123\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 69\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 217, train loss: 0.0142, loss: 0.0147, recall: 0.6016, mrr: 0.5534, time: 0.12657880783081055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 252\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 181\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 74\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 183\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 35, train loss: 0.0143, loss: 0.0143, recall: 0.6823, mrr: 0.6280, time: 0.20731258392333984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 13\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 69, train loss: 0.0143, loss: 0.0143, recall: 0.6719, mrr: 0.6380, time: 0.1495954990386963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 171\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 224, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.4901, time: 0.1606004238128662\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 252, train loss: 0.0144, loss: 0.0142, recall: 0.6797, mrr: 0.6452, time: 0.14299511909484863\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 189, train loss: 0.0143, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.180253267288208\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 248, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6302, time: 0.16585111618041992\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 104\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 183, train loss: 0.0144, loss: 0.0149, recall: 0.5781, mrr: 0.4992, time: 0.14095473289489746\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 16, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5807, time: 0.1956181526184082\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 123, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.5559, time: 0.19187378883361816\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 181, train loss: 0.0142, loss: 0.0146, recall: 0.6719, mrr: 0.6237, time: 0.10868239402770996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 13, train loss: 0.0142, loss: 0.0145, recall: 0.6562, mrr: 0.5214, time: 0.1315295696258545\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 171, train loss: 0.0144, loss: 0.0144, recall: 0.6979, mrr: 0.6311, time: 0.11683320999145508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 254, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.5905, time: 0.06750965118408203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 104, train loss: 0.0143, loss: 0.0147, recall: 0.5781, mrr: 0.4836, time: 0.12737774848937988\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 74, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5390, time: 0.18600058555603027\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 200\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 265\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 191, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6223, time: 0.0688624382019043\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 200, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5898, time: 0.0670156478881836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 265, train loss: 0.0144, loss: 0.0147, recall: 0.5729, mrr: 0.5403, time: 0.05772686004638672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 135\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 135, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5501, time: 0.06537580490112305\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 80\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 97\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 65\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 80, train loss: 0.0143, loss: 0.0146, recall: 0.6615, mrr: 0.5911, time: 0.08198070526123047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 52\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 97, train loss: 0.0144, loss: 0.0144, recall: 0.6510, mrr: 0.6369, time: 0.11561226844787598\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 73\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 267\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 34\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 65, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6094, time: 0.09561681747436523\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 242, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5234, time: 0.13147926330566406\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 52, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6288, time: 0.12439823150634766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 117, train loss: 0.0143, loss: 0.0147, recall: 0.6484, mrr: 0.5910, time: 0.08208799362182617\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 73, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4895, time: 0.11851954460144043\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 163\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 267, train loss: 0.0142, loss: 0.0146, recall: 0.5833, mrr: 0.5612, time: 0.1120913028717041\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 34, train loss: 0.0144, loss: 0.0145, recall: 0.6406, mrr: 0.5938, time: 0.14326214790344238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 102\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 102, train loss: 0.0144, loss: 0.0145, recall: 0.6615, mrr: 0.6044, time: 0.09514260292053223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 27\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 1, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.5926, time: 0.0684201717376709\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 163, train loss: 0.0143, loss: 0.0147, recall: 0.6667, mrr: 0.4780, time: 0.09326338768005371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 284\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 284, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.5844, time: 0.06302762031555176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 27, train loss: 0.0144, loss: 0.0142, recall: 0.7812, mrr: 0.6984, time: 0.055445194244384766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 261\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 261, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6956, time: 0.05838298797607422\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 160\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 119\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 160, train loss: 0.0143, loss: 0.0146, recall: 0.6641, mrr: 0.6146, time: 0.06830692291259766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 119, train loss: 0.0142, loss: 0.0144, recall: 0.7656, mrr: 0.7500, time: 0.05523061752319336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 118\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 90\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 230\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 178\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 100\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 106\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 106, train loss: 0.0142, loss: 0.0149, recall: 0.5625, mrr: 0.4875, time: 0.0717153549194336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 100, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6320, time: 0.07048559188842773\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 118, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6599, time: 0.05839395523071289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 90, train loss: 0.0144, loss: 0.0145, recall: 0.6328, mrr: 0.5740, time: 0.08003377914428711\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 230, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5440, time: 0.0757744312286377\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 178, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6190, time: 0.0625004768371582\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 186, train loss: 0.0143, loss: 0.0144, recall: 0.6992, mrr: 0.5725, time: 0.08328819274902344\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 115\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 287\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 205\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 103\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 292\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 115, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.6428, time: 0.08599138259887695\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 158\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 287, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5501, time: 0.07496857643127441\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 205, train loss: 0.0142, loss: 0.0144, recall: 0.7578, mrr: 0.6117, time: 0.0774233341217041\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 103, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.5661, time: 0.08993840217590332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 147\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 292, train loss: 0.0143, loss: 0.0148, recall: 0.5885, mrr: 0.5603, time: 0.17540740966796875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 285, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6250, time: 0.09427380561828613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 147, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6409, time: 0.1686553955078125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 158, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6100, time: 0.1756751537322998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 0, train loss: 0.0139, loss: 0.0152, recall: 0.5469, mrr: 0.3775, time: 0.18617630004882812\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 206\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 298\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 3, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5861, time: 0.07420110702514648\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 112, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6375, time: 0.07424139976501465\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 206, train loss: 0.0143, loss: 0.0145, recall: 0.6042, mrr: 0.5494, time: 0.07063555717468262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 108\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 298, train loss: 0.0142, loss: 0.0144, recall: 0.7083, mrr: 0.5721, time: 0.07176446914672852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 108, train loss: 0.0143, loss: 0.0145, recall: 0.6302, mrr: 0.5568, time: 0.09321856498718262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 136\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 136, train loss: 0.0143, loss: 0.0146, recall: 0.5469, mrr: 0.5071, time: 0.06073713302612305\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 109\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 238, train loss: 0.0143, loss: 0.0144, recall: 0.6927, mrr: 0.6056, time: 0.06827974319458008\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 111, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6393, time: 0.08317375183105469\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 109, train loss: 0.0144, loss: 0.0146, recall: 0.5898, mrr: 0.5479, time: 0.13724970817565918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 148, train loss: 0.0144, loss: 0.0144, recall: 0.7083, mrr: 0.6253, time: 0.08784031867980957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 264\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 91\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 297, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.6217, time: 0.09715604782104492\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 279\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 264, train loss: 0.0143, loss: 0.0143, recall: 0.7500, mrr: 0.6477, time: 0.11374163627624512\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 98\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 234, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6891, time: 0.08651041984558105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 247\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 247, train loss: 0.0144, loss: 0.0147, recall: 0.7031, mrr: 0.5725, time: 0.06972908973693848\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 125, train loss: 0.0144, loss: 0.0147, recall: 0.6328, mrr: 0.5630, time: 0.0747983455657959\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 91, train loss: 0.0143, loss: 0.0147, recall: 0.6615, mrr: 0.5559, time: 0.10502958297729492\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 279, train loss: 0.0141, loss: 0.0146, recall: 0.7422, mrr: 0.6980, time: 0.08528828620910645\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 157\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 157, train loss: 0.0143, loss: 0.0144, recall: 0.6406, mrr: 0.6043, time: 0.07446813583374023\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 98, train loss: 0.0144, loss: 0.0146, recall: 0.6172, mrr: 0.5344, time: 0.0828864574432373\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 21\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 21, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6754, time: 0.057875871658325195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 151\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 151, train loss: 0.0142, loss: 0.0144, recall: 0.6953, mrr: 0.6646, time: 0.06775045394897461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 45\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 45, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5794, time: 0.06032443046569824\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 208\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 203, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.5908, time: 0.06035351753234863\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 208, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5952, time: 0.06119871139526367\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 4\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 174\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 113, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.6077, time: 0.06834721565246582\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 71\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 71, train loss: 0.0143, loss: 0.0146, recall: 0.6354, mrr: 0.5727, time: 0.07744407653808594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 43\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 57\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 168\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 168, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5689, time: 0.060938119888305664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 4, train loss: 0.0143, loss: 0.0143, recall: 0.6953, mrr: 0.6305, time: 0.0734565258026123\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 156, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6450, time: 0.06349802017211914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 174, train loss: 0.0142, loss: 0.0146, recall: 0.6016, mrr: 0.5602, time: 0.057659149169921875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 43, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6523, time: 0.07066702842712402\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 57, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5316, time: 0.06413531303405762\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 235\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 235, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5985, time: 0.06400465965270996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 66\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 66, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5624, time: 0.0677037239074707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 253\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 294\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 18\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 256\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 256, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.6309, time: 0.06833124160766602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 84\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 84, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5408, time: 0.07706522941589355\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 253, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6102, time: 0.06745052337646484\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 294, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.5938, time: 0.07027220726013184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 18, train loss: 0.0143, loss: 0.0146, recall: 0.6302, mrr: 0.5913, time: 0.07448005676269531\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 225\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 210\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 39\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 225, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6697, time: 0.07229328155517578\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 210, train loss: 0.0142, loss: 0.0147, recall: 0.5417, mrr: 0.5115, time: 0.07108783721923828\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 152, train loss: 0.0144, loss: 0.0147, recall: 0.5859, mrr: 0.5428, time: 0.07433915138244629\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 266, train loss: 0.0142, loss: 0.0143, recall: 0.7344, mrr: 0.6526, time: 0.06924176216125488\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 39, train loss: 0.0142, loss: 0.0146, recall: 0.6250, mrr: 0.5569, time: 0.0731968879699707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 272\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 272, train loss: 0.0143, loss: 0.0143, recall: 0.6667, mrr: 0.6201, time: 0.0754239559173584\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 226\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 76\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 226, train loss: 0.0143, loss: 0.0146, recall: 0.5625, mrr: 0.5076, time: 0.07310771942138672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 76, train loss: 0.0144, loss: 0.0147, recall: 0.6146, mrr: 0.5184, time: 0.10560894012451172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 258, train loss: 0.0144, loss: 0.0147, recall: 0.5781, mrr: 0.5617, time: 0.09571003913879395\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 9\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 202\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 14\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 77\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 9, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.6510, time: 0.07389092445373535\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 202, train loss: 0.0143, loss: 0.0146, recall: 0.6953, mrr: 0.6698, time: 0.08497023582458496\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 14, train loss: 0.0143, loss: 0.0144, recall: 0.6510, mrr: 0.5925, time: 0.07862043380737305\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 77, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.5484, time: 0.09525561332702637\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 105, train loss: 0.0144, loss: 0.0147, recall: 0.5391, mrr: 0.5100, time: 0.11576509475708008\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 137, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5836, time: 0.07776403427124023\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 149\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 149, train loss: 0.0141, loss: 0.0144, recall: 0.6953, mrr: 0.6029, time: 0.07766604423522949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 167\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 142\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 50\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 167, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6945, time: 0.06848621368408203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 128\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 128, train loss: 0.0143, loss: 0.0146, recall: 0.6328, mrr: 0.5388, time: 0.06186628341674805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 142, train loss: 0.0144, loss: 0.0144, recall: 0.7031, mrr: 0.6676, time: 0.0738525390625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 46\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 50, train loss: 0.0142, loss: 0.0147, recall: 0.6094, mrr: 0.5639, time: 0.062021493911743164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 46, train loss: 0.0142, loss: 0.0143, recall: 0.7109, mrr: 0.6641, time: 0.06321024894714355\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 44\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 44, train loss: 0.0142, loss: 0.0143, recall: 0.6875, mrr: 0.6382, time: 0.06374835968017578\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 138\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 138, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.6432, time: 0.058094024658203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 101\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 101, train loss: 0.0142, loss: 0.0147, recall: 0.6328, mrr: 0.5452, time: 0.06108498573303223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 211, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.5194, time: 0.06161761283874512\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 193\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 190\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 131\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 11\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 11, train loss: 0.0145, loss: 0.0146, recall: 0.5703, mrr: 0.5253, time: 0.08378124237060547\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 38\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 70\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 175\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 221\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 221, train loss: 0.0143, loss: 0.0144, recall: 0.7135, mrr: 0.6486, time: 0.07735824584960938\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 193, train loss: 0.0144, loss: 0.0145, recall: 0.6042, mrr: 0.5546, time: 0.08913588523864746\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 190, train loss: 0.0143, loss: 0.0149, recall: 0.5885, mrr: 0.4434, time: 0.09113478660583496\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 131, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.7017, time: 0.07971549034118652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 38, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6398, time: 0.09869217872619629\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 70, train loss: 0.0142, loss: 0.0144, recall: 0.6302, mrr: 0.5645, time: 0.0918726921081543\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 175, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6335, time: 0.08940005302429199\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 107\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 107, train loss: 0.0143, loss: 0.0146, recall: 0.6289, mrr: 0.5212, time: 0.07374167442321777\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 114\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 114, train loss: 0.0144, loss: 0.0147, recall: 0.6250, mrr: 0.5761, time: 0.07955074310302734\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 55\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 55, train loss: 0.0145, loss: 0.0144, recall: 0.6719, mrr: 0.5973, time: 0.07529592514038086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 58\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 58, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6246, time: 0.06592655181884766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 241\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 241, train loss: 0.0142, loss: 0.0147, recall: 0.6641, mrr: 0.5533, time: 0.07714509963989258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 48\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 48, train loss: 0.0141, loss: 0.0144, recall: 0.6797, mrr: 0.6253, time: 0.07335162162780762\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 42\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 42, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.6263, time: 0.06889724731445312\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 231\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 222, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6531, time: 0.07622265815734863\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 63\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 231, train loss: 0.0143, loss: 0.0147, recall: 0.5885, mrr: 0.4687, time: 0.12737655639648438\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 260\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 260, train loss: 0.0143, loss: 0.0142, recall: 0.7500, mrr: 0.7233, time: 0.06426644325256348\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 7\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 164, train loss: 0.0144, loss: 0.0146, recall: 0.5859, mrr: 0.5257, time: 0.07686948776245117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 213\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 63, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6448, time: 0.09629011154174805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 257\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 257, train loss: 0.0142, loss: 0.0144, recall: 0.7344, mrr: 0.5729, time: 0.08345460891723633\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 7, train loss: 0.0144, loss: 0.0146, recall: 0.6250, mrr: 0.6038, time: 0.07440948486328125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 213, train loss: 0.0144, loss: 0.0148, recall: 0.5781, mrr: 0.4879, time: 0.0930640697479248\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 227, train loss: 0.0143, loss: 0.0147, recall: 0.6172, mrr: 0.6003, time: 0.1089468002319336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 262, train loss: 0.0143, loss: 0.0145, recall: 0.6250, mrr: 0.6031, time: 0.08765840530395508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 133, train loss: 0.0143, loss: 0.0144, recall: 0.7396, mrr: 0.6594, time: 0.11133074760437012\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 180\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 180, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.6810, time: 0.04430198669433594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 154\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 154, train loss: 0.0143, loss: 0.0147, recall: 0.5469, mrr: 0.5172, time: 0.05193018913269043\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 67\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 67, train loss: 0.0143, loss: 0.0141, recall: 0.7891, mrr: 0.7600, time: 0.05188775062561035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 145, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6725, time: 0.05379295349121094\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 268\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 268, train loss: 0.0143, loss: 0.0146, recall: 0.6172, mrr: 0.5504, time: 0.05751681327819824\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 47\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 47, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.6680, time: 0.05481410026550293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 187\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 187, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6389, time: 0.06655073165893555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 22\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 22, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6507, time: 0.05398440361022949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 41\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 41, train loss: 0.0143, loss: 0.0146, recall: 0.7656, mrr: 0.7190, time: 0.04988598823547363\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 155\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 155, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5803, time: 0.056839942932128906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 79\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 79, train loss: 0.0144, loss: 0.0142, recall: 0.7031, mrr: 0.6241, time: 0.057300567626953125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 129, train loss: 0.0142, loss: 0.0142, recall: 0.7734, mrr: 0.7216, time: 0.046645164489746094\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 116\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 116, train loss: 0.0144, loss: 0.0148, recall: 0.5833, mrr: 0.5042, time: 0.05756258964538574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 214\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 214, train loss: 0.0144, loss: 0.0143, recall: 0.7734, mrr: 0.6698, time: 0.05048942565917969\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 209, train loss: 0.0144, loss: 0.0144, recall: 0.6953, mrr: 0.6797, time: 0.05682635307312012\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 141\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 141, train loss: 0.0143, loss: 0.0142, recall: 0.7109, mrr: 0.6385, time: 0.051212310791015625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 176, train loss: 0.0143, loss: 0.0141, recall: 0.7812, mrr: 0.7141, time: 0.04899764060974121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 36\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 36, train loss: 0.0143, loss: 0.0144, recall: 0.7422, mrr: 0.6885, time: 0.057253360748291016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 144\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 144, train loss: 0.0144, loss: 0.0145, recall: 0.6979, mrr: 0.6681, time: 0.05612802505493164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 150\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 150, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6303, time: 0.05973982810974121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 5, train loss: 0.0144, loss: 0.0144, recall: 0.6797, mrr: 0.6184, time: 0.06067299842834473\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 195, train loss: 0.0144, loss: 0.0145, recall: 0.7656, mrr: 0.7161, time: 0.04186201095581055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 251\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 251, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6435, time: 0.055828094482421875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 139\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 139, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5710, time: 0.0568842887878418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 245\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 245, train loss: 0.0143, loss: 0.0143, recall: 0.6484, mrr: 0.6020, time: 0.05926012992858887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 30\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 30, train loss: 0.0143, loss: 0.0146, recall: 0.5859, mrr: 0.5716, time: 0.07470822334289551\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 263\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 263, train loss: 0.0143, loss: 0.0147, recall: 0.6094, mrr: 0.5726, time: 0.05115818977355957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 28\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 28, train loss: 0.0143, loss: 0.0143, recall: 0.7344, mrr: 0.7188, time: 0.04690909385681152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 53\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 53, train loss: 0.0144, loss: 0.0146, recall: 0.6615, mrr: 0.5601, time: 0.06350588798522949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 93\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 93, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5674, time: 0.060492515563964844\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 274\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 274, train loss: 0.0143, loss: 0.0147, recall: 0.5625, mrr: 0.5203, time: 0.06460309028625488\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 12\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 12, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6660, time: 0.04507327079772949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 6, train loss: 0.0142, loss: 0.0143, recall: 0.6562, mrr: 0.6099, time: 0.049303531646728516\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 277, train loss: 0.0144, loss: 0.0148, recall: 0.5469, mrr: 0.4754, time: 0.058405399322509766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 94\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 94, train loss: 0.0142, loss: 0.0145, recall: 0.7031, mrr: 0.6829, time: 0.056479692459106445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 13:08:54,045 | server.py:281 | fit_round received 297 results and 3 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 143\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 143, train loss: 0.0144, loss: 0.0150, recall: 0.5312, mrr: 0.4944, time: 0.054724693298339844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 13:08:54,411 | server.py:215 | evaluate_round: strategy sampled 150 clients (out of 300)\n",
      "DEBUG flower 2022-06-17 13:10:52,278 | server.py:227 | evaluate_round received 150 results and 0 failures\n",
      "DEBUG flower 2022-06-17 13:10:52,279 | server.py:269 | fit_round: strategy sampled 300 clients (out of 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 294\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 214\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 78\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 150\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 231\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 196\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 87\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 102\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 44\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 90\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 65\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 52\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 202\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 69\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 196, train loss: 0.0144, loss: 0.0145, recall: 0.6458, mrr: 0.6007, time: 0.14312243461608887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 52, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6288, time: 0.1681966781616211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 202, train loss: 0.0143, loss: 0.0146, recall: 0.6953, mrr: 0.6698, time: 0.1744556427001953\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 294, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.5938, time: 0.17123103141784668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 214, train loss: 0.0144, loss: 0.0143, recall: 0.7734, mrr: 0.6698, time: 0.167633056640625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 78, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5217, time: 0.18990802764892578\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 69, train loss: 0.0143, loss: 0.0143, recall: 0.6719, mrr: 0.6380, time: 0.16157293319702148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 150, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6303, time: 0.18465590476989746\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 289, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6410, time: 0.17998719215393066\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 231, train loss: 0.0143, loss: 0.0147, recall: 0.5885, mrr: 0.4687, time: 0.19967174530029297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 234, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6891, time: 0.18642735481262207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 87, train loss: 0.0143, loss: 0.0144, recall: 0.6797, mrr: 0.6105, time: 0.1809699535369873\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 102, train loss: 0.0144, loss: 0.0145, recall: 0.6615, mrr: 0.6044, time: 0.18365931510925293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 44, train loss: 0.0142, loss: 0.0143, recall: 0.6875, mrr: 0.6382, time: 0.17987465858459473\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 90, train loss: 0.0144, loss: 0.0145, recall: 0.6328, mrr: 0.5740, time: 0.18407320976257324\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 65, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6094, time: 0.16061663627624512\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 80\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 130\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 169\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 4\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 168\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 100\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 68\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 136\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 190\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 166\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 174\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 183\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 130, train loss: 0.0143, loss: 0.0142, recall: 0.6953, mrr: 0.6673, time: 0.14149904251098633\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 190, train loss: 0.0143, loss: 0.0149, recall: 0.5885, mrr: 0.4434, time: 0.16048121452331543\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 212\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 247\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 183, train loss: 0.0144, loss: 0.0149, recall: 0.5781, mrr: 0.4992, time: 0.16172075271606445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 216\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 80, train loss: 0.0143, loss: 0.0146, recall: 0.6615, mrr: 0.5911, time: 0.16064167022705078\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 169, train loss: 0.0143, loss: 0.0146, recall: 0.6042, mrr: 0.5390, time: 0.16531991958618164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 4, train loss: 0.0143, loss: 0.0143, recall: 0.6953, mrr: 0.6305, time: 0.16984081268310547\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 168, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5689, time: 0.1561603546142578\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 100, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6320, time: 0.16552352905273438\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 68, train loss: 0.0141, loss: 0.0145, recall: 0.6250, mrr: 0.5677, time: 0.16849398612976074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 136, train loss: 0.0143, loss: 0.0146, recall: 0.5469, mrr: 0.5071, time: 0.17588329315185547\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 212, train loss: 0.0142, loss: 0.0147, recall: 0.5938, mrr: 0.5688, time: 0.16320538520812988\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 166, train loss: 0.0142, loss: 0.0149, recall: 0.5547, mrr: 0.4693, time: 0.14769935607910156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 174, train loss: 0.0142, loss: 0.0146, recall: 0.6016, mrr: 0.5602, time: 0.14746356010437012\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 247, train loss: 0.0144, loss: 0.0147, recall: 0.7031, mrr: 0.5725, time: 0.14650583267211914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 76\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 216, train loss: 0.0143, loss: 0.0141, recall: 0.7500, mrr: 0.7083, time: 0.1734154224395752\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 76, train loss: 0.0144, loss: 0.0147, recall: 0.6146, mrr: 0.5184, time: 0.21813106536865234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 208\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 132\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 56\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 263\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 43\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 15\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 192\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 255\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 232\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 228\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 271\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 132, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6432, time: 0.13405227661132812\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 208, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5952, time: 0.1347181797027588\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 15, train loss: 0.0142, loss: 0.0145, recall: 0.6641, mrr: 0.5732, time: 0.16394925117492676\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 35\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 233\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 228, train loss: 0.0143, loss: 0.0146, recall: 0.5781, mrr: 0.5052, time: 0.16927194595336914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 263, train loss: 0.0143, loss: 0.0147, recall: 0.6094, mrr: 0.5726, time: 0.15001893043518066\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 56, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6589, time: 0.15584921836853027\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 117, train loss: 0.0143, loss: 0.0147, recall: 0.6484, mrr: 0.5910, time: 0.10180425643920898\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 43, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6523, time: 0.15742087364196777\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 176, train loss: 0.0143, loss: 0.0141, recall: 0.7812, mrr: 0.7141, time: 0.09366798400878906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 35, train loss: 0.0143, loss: 0.0143, recall: 0.6823, mrr: 0.6280, time: 0.12961959838867188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 233, train loss: 0.0144, loss: 0.0146, recall: 0.6875, mrr: 0.6099, time: 0.1501309871673584\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 192, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6246, time: 0.15586566925048828\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 255, train loss: 0.0142, loss: 0.0146, recall: 0.6328, mrr: 0.5983, time: 0.16481399536132812\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 232, train loss: 0.0144, loss: 0.0150, recall: 0.5781, mrr: 0.4168, time: 0.1668694019317627\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 71\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 271, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5854, time: 0.1543562412261963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 71, train loss: 0.0143, loss: 0.0146, recall: 0.6354, mrr: 0.5727, time: 0.06795048713684082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 110\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 95\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 147\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 25\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 278\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 73\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 206\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 85\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 110, train loss: 0.0145, loss: 0.0146, recall: 0.6172, mrr: 0.5598, time: 0.18392682075500488\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 249\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 62\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 109\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 17\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 119\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 85, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.7047, time: 0.15732312202453613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 95, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5624, time: 0.18509840965270996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 147, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6409, time: 0.1913466453552246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 249, train loss: 0.0144, loss: 0.0148, recall: 0.5859, mrr: 0.5083, time: 0.16683578491210938\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 188, train loss: 0.0144, loss: 0.0149, recall: 0.5000, mrr: 0.4807, time: 0.192518949508667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 17, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.5509, time: 0.1606748104095459\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 254, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.5905, time: 0.16838312149047852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 119, train loss: 0.0142, loss: 0.0144, recall: 0.7656, mrr: 0.7500, time: 0.13729000091552734\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 25, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.6276, time: 0.16704082489013672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 278, train loss: 0.0144, loss: 0.0146, recall: 0.5781, mrr: 0.5431, time: 0.20573854446411133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 73, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4895, time: 0.23619747161865234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 129, train loss: 0.0142, loss: 0.0142, recall: 0.7734, mrr: 0.7216, time: 0.15875530242919922\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 206, train loss: 0.0143, loss: 0.0145, recall: 0.6042, mrr: 0.5494, time: 0.1890876293182373\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 62, train loss: 0.0143, loss: 0.0145, recall: 0.6797, mrr: 0.6160, time: 0.20694732666015625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 109, train loss: 0.0144, loss: 0.0146, recall: 0.5898, mrr: 0.5479, time: 0.2044811248779297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 260\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 94\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 285, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6250, time: 0.07156872749328613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 253\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 142\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 74\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 273, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5653, time: 0.08124423027038574\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 104\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 260, train loss: 0.0143, loss: 0.0142, recall: 0.7500, mrr: 0.7233, time: 0.07642173767089844\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 94, train loss: 0.0142, loss: 0.0145, recall: 0.7031, mrr: 0.6829, time: 0.0848855972290039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 253, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6102, time: 0.09419107437133789\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 142, train loss: 0.0144, loss: 0.0144, recall: 0.7031, mrr: 0.6676, time: 0.08639764785766602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 104, train loss: 0.0143, loss: 0.0147, recall: 0.5781, mrr: 0.4836, time: 0.08066391944885254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 74, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5390, time: 0.11295413970947266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 172, train loss: 0.0143, loss: 0.0144, recall: 0.6719, mrr: 0.6219, time: 0.9866149425506592\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 11\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 75\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 163\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 53\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 36\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 298\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 299\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 103\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 8\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 79\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 264\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 11, train loss: 0.0145, loss: 0.0146, recall: 0.5703, mrr: 0.5253, time: 0.13327765464782715\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 53, train loss: 0.0144, loss: 0.0146, recall: 0.6615, mrr: 0.5601, time: 0.13735246658325195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 36, train loss: 0.0143, loss: 0.0144, recall: 0.7422, mrr: 0.6885, time: 0.12990880012512207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 103, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.5661, time: 0.17182350158691406\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 112, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6375, time: 0.17373895645141602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 8, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6038, time: 0.16260123252868652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 79, train loss: 0.0144, loss: 0.0142, recall: 0.7031, mrr: 0.6241, time: 0.16445684432983398\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 277, train loss: 0.0144, loss: 0.0148, recall: 0.5469, mrr: 0.4754, time: 0.17782831192016602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 105, train loss: 0.0144, loss: 0.0147, recall: 0.5391, mrr: 0.5100, time: 0.18110418319702148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 164, train loss: 0.0144, loss: 0.0146, recall: 0.5859, mrr: 0.5257, time: 0.17205810546875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 264, train loss: 0.0143, loss: 0.0143, recall: 0.7500, mrr: 0.6477, time: 0.17265939712524414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 298, train loss: 0.0142, loss: 0.0144, recall: 0.7083, mrr: 0.5721, time: 0.14680171012878418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 163, train loss: 0.0143, loss: 0.0147, recall: 0.6667, mrr: 0.4780, time: 0.1729729175567627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m   out=out, **kwargs)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m   ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 28\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 28, train loss: 0.0143, loss: 0.0143, recall: 0.7344, mrr: 0.7188, time: 0.04999828338623047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 280\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 280, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6083, time: 0.06115269660949707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 236\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 236, train loss: 0.0144, loss: 0.0142, recall: 0.6719, mrr: 0.6602, time: 0.05760931968688965\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 288\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 141\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 141, train loss: 0.0143, loss: 0.0142, recall: 0.7109, mrr: 0.6385, time: 0.06617474555969238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 283\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 283, train loss: 0.0144, loss: 0.0144, recall: 0.6172, mrr: 0.5931, time: 0.06564855575561523\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 143\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 288, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.1065664291381836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 213\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 149\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 143, train loss: 0.0144, loss: 0.0150, recall: 0.5312, mrr: 0.4944, time: 0.07930469512939453\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 291, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6156, time: 0.07837176322937012\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 213, train loss: 0.0144, loss: 0.0148, recall: 0.5781, mrr: 0.4879, time: 0.06291604042053223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 149, train loss: 0.0141, loss: 0.0144, recall: 0.6953, mrr: 0.6029, time: 0.06509184837341309\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 32\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 16\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 32, train loss: 0.0143, loss: 0.0142, recall: 0.7188, mrr: 0.6708, time: 0.0830845832824707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 16, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5807, time: 0.0728909969329834\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 111, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6393, time: 0.0668337345123291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 246, train loss: 0.0143, loss: 0.0146, recall: 0.7109, mrr: 0.5932, time: 0.053720712661743164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 197\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 197, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6350, time: 0.057755231857299805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 180\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 218\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 180, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.6810, time: 0.07414770126342773\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 98\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 218, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6424, time: 0.07588553428649902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 282\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 282, train loss: 0.0143, loss: 0.0145, recall: 0.8281, mrr: 0.6672, time: 0.060051679611206055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 220\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 98, train loss: 0.0144, loss: 0.0146, recall: 0.6172, mrr: 0.5344, time: 0.11757922172546387\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 47\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 47, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.6680, time: 0.0636138916015625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 50\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 50, train loss: 0.0142, loss: 0.0147, recall: 0.6094, mrr: 0.5639, time: 0.05935502052307129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 220, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6339, time: 0.07406902313232422\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 219, train loss: 0.0142, loss: 0.0148, recall: 0.6406, mrr: 0.5796, time: 0.0778968334197998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 124\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 124, train loss: 0.0143, loss: 0.0144, recall: 0.7266, mrr: 0.6259, time: 0.05866599082946777\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 223, train loss: 0.0144, loss: 0.0144, recall: 0.6250, mrr: 0.5803, time: 0.06793379783630371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 226\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 51\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 63\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 161\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 97\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 7\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 158\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 115\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 77\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 97, train loss: 0.0144, loss: 0.0144, recall: 0.6510, mrr: 0.6369, time: 0.18613767623901367\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 115, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.6428, time: 0.15374970436096191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 158, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6100, time: 0.1830894947052002\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 226, train loss: 0.0143, loss: 0.0146, recall: 0.5625, mrr: 0.5076, time: 0.1917872428894043\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 77, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.5484, time: 0.17412090301513672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 1, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.5926, time: 0.1818256378173828\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 34\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 51, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5901, time: 0.21399474143981934\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 148, train loss: 0.0144, loss: 0.0144, recall: 0.7083, mrr: 0.6253, time: 0.20776677131652832\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 266, train loss: 0.0142, loss: 0.0143, recall: 0.7344, mrr: 0.6526, time: 0.18888068199157715\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 63, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6448, time: 0.18275713920593262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 3, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5861, time: 0.1932840347290039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 161, train loss: 0.0142, loss: 0.0149, recall: 0.4844, mrr: 0.4410, time: 0.1949751377105713\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 7, train loss: 0.0144, loss: 0.0146, recall: 0.6250, mrr: 0.6038, time: 0.19117474555969238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 34, train loss: 0.0144, loss: 0.0145, recall: 0.6406, mrr: 0.5938, time: 0.0801248550415039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 89\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 89, train loss: 0.0143, loss: 0.0149, recall: 0.5729, mrr: 0.5129, time: 0.06183576583862305\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 258, train loss: 0.0144, loss: 0.0147, recall: 0.5781, mrr: 0.5617, time: 0.05815291404724121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 205\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 118\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 127\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 265\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 205, train loss: 0.0142, loss: 0.0144, recall: 0.7578, mrr: 0.6117, time: 0.07813620567321777\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 286\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 118, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6599, time: 0.06757426261901855\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 127, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.07772088050842285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 244\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 244, train loss: 0.0142, loss: 0.0144, recall: 0.6458, mrr: 0.5933, time: 0.0853269100189209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 96\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 96, train loss: 0.0142, loss: 0.0148, recall: 0.5938, mrr: 0.5070, time: 0.0757904052734375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 24\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 265, train loss: 0.0144, loss: 0.0147, recall: 0.5729, mrr: 0.5403, time: 0.0723423957824707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 286, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5820, time: 0.10088729858398438\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 24, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.5940, time: 0.06644558906555176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 37\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 272\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 272, train loss: 0.0143, loss: 0.0143, recall: 0.6667, mrr: 0.6201, time: 0.07422637939453125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 270\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 270, train loss: 0.0143, loss: 0.0142, recall: 0.7031, mrr: 0.6734, time: 0.07113337516784668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 37, train loss: 0.0144, loss: 0.0147, recall: 0.6133, mrr: 0.5169, time: 0.06730961799621582\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 215, train loss: 0.0144, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.0765678882598877\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 38\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 48\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 38, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6398, time: 0.0656270980834961\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 48, train loss: 0.0141, loss: 0.0144, recall: 0.6797, mrr: 0.6253, time: 0.06499886512756348\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 125, train loss: 0.0144, loss: 0.0147, recall: 0.6328, mrr: 0.5630, time: 0.060224294662475586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 248\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 29\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 29, train loss: 0.0145, loss: 0.0146, recall: 0.5781, mrr: 0.5310, time: 0.049398183822631836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 248, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6302, time: 0.06773495674133301\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 160\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 160, train loss: 0.0143, loss: 0.0146, recall: 0.6641, mrr: 0.6146, time: 0.06566882133483887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 59\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 59, train loss: 0.0142, loss: 0.0145, recall: 0.6094, mrr: 0.6016, time: 0.052049875259399414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 235\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 235, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5985, time: 0.06379985809326172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 114\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 114, train loss: 0.0144, loss: 0.0147, recall: 0.6250, mrr: 0.5761, time: 0.0686192512512207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 245\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 201\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 193\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 92\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 217\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 267\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 261\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 81\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 284\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 67\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 252\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 204\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 99\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 217, train loss: 0.0142, loss: 0.0147, recall: 0.6016, mrr: 0.5534, time: 0.16797518730163574\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 284, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.5844, time: 0.15991616249084473\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 245, train loss: 0.0143, loss: 0.0143, recall: 0.6484, mrr: 0.6020, time: 0.17164969444274902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 99, train loss: 0.0141, loss: 0.0142, recall: 0.6797, mrr: 0.6686, time: 0.1685779094696045\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 201, train loss: 0.0144, loss: 0.0144, recall: 0.6562, mrr: 0.6167, time: 0.17768526077270508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 227, train loss: 0.0143, loss: 0.0147, recall: 0.6172, mrr: 0.6003, time: 0.19348740577697754\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 193, train loss: 0.0144, loss: 0.0145, recall: 0.6042, mrr: 0.5546, time: 0.17087960243225098\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 92, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6057, time: 0.1843714714050293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 267, train loss: 0.0142, loss: 0.0146, recall: 0.5833, mrr: 0.5612, time: 0.1688840389251709\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 261, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6956, time: 0.17831897735595703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 81, train loss: 0.0144, loss: 0.0146, recall: 0.5469, mrr: 0.5155, time: 0.18706154823303223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 67, train loss: 0.0143, loss: 0.0141, recall: 0.7891, mrr: 0.7600, time: 0.15757346153259277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 252, train loss: 0.0144, loss: 0.0142, recall: 0.6797, mrr: 0.6452, time: 0.16266274452209473\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 204, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.6099, time: 0.17450451850891113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 187\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 82\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 187, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6389, time: 0.0729527473449707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 170\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 170, train loss: 0.0143, loss: 0.0146, recall: 0.6094, mrr: 0.5098, time: 0.05925488471984863\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 122\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 207, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6630, time: 0.06970477104187012\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 122, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6359, time: 0.060949087142944336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 239\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 49\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 225\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 64\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 84\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 239, train loss: 0.0143, loss: 0.0139, recall: 0.8281, mrr: 0.7766, time: 0.0849909782409668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 19\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 49, train loss: 0.0144, loss: 0.0142, recall: 0.6927, mrr: 0.6710, time: 0.0851290225982666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 297, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.6217, time: 0.08044171333312988\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 225, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6697, time: 0.08975958824157715\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 181\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 64, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5874, time: 0.08294916152954102\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 84, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5408, time: 0.09543585777282715\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 137, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5836, time: 0.10461211204528809\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 19, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5641, time: 0.09896397590637207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 181, train loss: 0.0142, loss: 0.0146, recall: 0.6719, mrr: 0.6237, time: 0.09128165245056152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 203, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.5908, time: 0.06573009490966797\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 185, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.6393, time: 0.06492424011230469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 116\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 269\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 133, train loss: 0.0143, loss: 0.0144, recall: 0.7396, mrr: 0.6594, time: 0.08570432662963867\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 57\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 116, train loss: 0.0144, loss: 0.0148, recall: 0.5833, mrr: 0.5042, time: 0.07944130897521973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 269, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6773, time: 0.07519197463989258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 57, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5316, time: 0.05616903305053711\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 22\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 22, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6507, time: 0.06094169616699219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 153\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 153, train loss: 0.0143, loss: 0.0146, recall: 0.7188, mrr: 0.6615, time: 0.06742143630981445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 20\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 33\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 20, train loss: 0.0144, loss: 0.0146, recall: 0.6458, mrr: 0.5633, time: 0.0683903694152832\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 33, train loss: 0.0144, loss: 0.0146, recall: 0.6823, mrr: 0.6515, time: 0.0727682113647461\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 42\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 146\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 287\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 229\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 42, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.6263, time: 0.07358479499816895\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 146, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.5919, time: 0.07484793663024902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 251\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 287, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5501, time: 0.06566071510314941\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 23\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 126\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 229, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5677, time: 0.08759522438049316\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 257\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 145, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6725, time: 0.11115026473999023\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 209, train loss: 0.0144, loss: 0.0144, recall: 0.6953, mrr: 0.6797, time: 0.11709308624267578\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 251, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6435, time: 0.09182929992675781\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 23, train loss: 0.0143, loss: 0.0144, recall: 0.6250, mrr: 0.5845, time: 0.08709430694580078\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 126, train loss: 0.0143, loss: 0.0141, recall: 0.7734, mrr: 0.6767, time: 0.11984133720397949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 257, train loss: 0.0142, loss: 0.0144, recall: 0.7344, mrr: 0.5729, time: 0.11716008186340332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 144\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 171\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 171, train loss: 0.0144, loss: 0.0144, recall: 0.6979, mrr: 0.6311, time: 0.06401538848876953\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 39\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 39, train loss: 0.0142, loss: 0.0146, recall: 0.6250, mrr: 0.5569, time: 0.06568646430969238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 144, train loss: 0.0144, loss: 0.0145, recall: 0.6979, mrr: 0.6681, time: 0.0650625228881836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 221\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 221, train loss: 0.0143, loss: 0.0144, recall: 0.7135, mrr: 0.6486, time: 0.0797719955444336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 93\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 93, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5674, time: 0.08962726593017578\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 162\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 162, train loss: 0.0144, loss: 0.0145, recall: 0.5938, mrr: 0.5670, time: 0.06962251663208008\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 83\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 107\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 83, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4795, time: 0.09531903266906738\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 182\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 108\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 41\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 107, train loss: 0.0143, loss: 0.0146, recall: 0.6289, mrr: 0.5212, time: 0.11656308174133301\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 243\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 243, train loss: 0.0143, loss: 0.0145, recall: 0.7109, mrr: 0.6596, time: 0.09873652458190918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 182, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5159, time: 0.1039426326751709\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 6, train loss: 0.0142, loss: 0.0143, recall: 0.6562, mrr: 0.6099, time: 0.09926176071166992\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 108, train loss: 0.0143, loss: 0.0145, recall: 0.6302, mrr: 0.5568, time: 0.13651204109191895\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 210\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 0, train loss: 0.0139, loss: 0.0152, recall: 0.5469, mrr: 0.3775, time: 0.11932563781738281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 41, train loss: 0.0143, loss: 0.0146, recall: 0.7656, mrr: 0.7190, time: 0.07555484771728516\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 242, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5234, time: 0.07014822959899902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 210, train loss: 0.0142, loss: 0.0147, recall: 0.5417, mrr: 0.5115, time: 0.06873154640197754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 131339 MiB, 2515 objects, write throughput 63 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 154\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 13\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 72\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 268\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 121, train loss: 0.0144, loss: 0.0142, recall: 0.7500, mrr: 0.7164, time: 0.07020211219787598\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 154, train loss: 0.0143, loss: 0.0147, recall: 0.5469, mrr: 0.5172, time: 0.08549094200134277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 13, train loss: 0.0142, loss: 0.0145, recall: 0.6562, mrr: 0.5214, time: 0.07243108749389648\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 72, train loss: 0.0143, loss: 0.0148, recall: 0.5938, mrr: 0.5529, time: 0.07860898971557617\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 268, train loss: 0.0143, loss: 0.0146, recall: 0.6172, mrr: 0.5504, time: 0.07660079002380371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 18\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 18, train loss: 0.0143, loss: 0.0146, recall: 0.6302, mrr: 0.5913, time: 0.07854652404785156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 14\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 70\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 14, train loss: 0.0143, loss: 0.0144, recall: 0.6510, mrr: 0.5925, time: 0.06715679168701172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 70, train loss: 0.0142, loss: 0.0144, recall: 0.6302, mrr: 0.5645, time: 0.06549715995788574\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 262, train loss: 0.0143, loss: 0.0145, recall: 0.6250, mrr: 0.6031, time: 0.05913114547729492\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 175\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 178\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 175, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6335, time: 0.05504465103149414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 178, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6190, time: 0.05079936981201172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 256\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 198\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 138\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 222, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6531, time: 0.08353114128112793\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 256, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.6309, time: 0.06992912292480469\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 26\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 167\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 179\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 159\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 198, train loss: 0.0144, loss: 0.0143, recall: 0.6875, mrr: 0.6510, time: 0.06866121292114258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 237\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 138, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.6432, time: 0.1060495376586914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 26, train loss: 0.0143, loss: 0.0144, recall: 0.5938, mrr: 0.5749, time: 0.10524106025695801\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 167, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6945, time: 0.09054422378540039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 179, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.6276, time: 0.09064459800720215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 159, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.5677, time: 0.08901405334472656\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 237, train loss: 0.0142, loss: 0.0142, recall: 0.6719, mrr: 0.6719, time: 0.09909439086914062\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 281, train loss: 0.0143, loss: 0.0143, recall: 0.7578, mrr: 0.7477, time: 0.06355166435241699\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 151\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 31\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 135\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 275\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 199\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 120\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 151, train loss: 0.0142, loss: 0.0144, recall: 0.6953, mrr: 0.6646, time: 0.14661097526550293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 46\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 10, train loss: 0.0142, loss: 0.0142, recall: 0.7344, mrr: 0.6068, time: 0.13234639167785645\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 241\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 135, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5501, time: 0.16384053230285645\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 275, train loss: 0.0142, loss: 0.0146, recall: 0.6562, mrr: 0.6189, time: 0.16447830200195312\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 139\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 199, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.5859, time: 0.15274477005004883\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 30\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 31, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6615, time: 0.18397974967956543\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 27\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 120, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5417, time: 0.0910184383392334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 46, train loss: 0.0142, loss: 0.0143, recall: 0.7109, mrr: 0.6641, time: 0.12148618698120117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 241, train loss: 0.0142, loss: 0.0147, recall: 0.6641, mrr: 0.5533, time: 0.12816262245178223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 157\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 157, train loss: 0.0143, loss: 0.0144, recall: 0.6406, mrr: 0.6043, time: 0.08658242225646973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 211, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.5194, time: 0.11160397529602051\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 186, train loss: 0.0143, loss: 0.0144, recall: 0.6992, mrr: 0.5725, time: 0.11484766006469727\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 184, train loss: 0.0143, loss: 0.0145, recall: 0.7266, mrr: 0.6857, time: 0.16045665740966797\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 139, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5710, time: 0.1110076904296875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 30, train loss: 0.0143, loss: 0.0146, recall: 0.5859, mrr: 0.5716, time: 0.10396170616149902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 27, train loss: 0.0144, loss: 0.0142, recall: 0.7812, mrr: 0.6984, time: 0.12572264671325684\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 86\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 86, train loss: 0.0143, loss: 0.0146, recall: 0.5990, mrr: 0.5689, time: 0.08064627647399902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 259, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6214, time: 0.0787355899810791\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 58\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 58, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6246, time: 0.06547713279724121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 200\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 189\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 189, train loss: 0.0143, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.08920097351074219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 55\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 55, train loss: 0.0145, loss: 0.0144, recall: 0.6719, mrr: 0.5973, time: 0.07531118392944336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 200, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5898, time: 0.07016825675964355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 106\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 106, train loss: 0.0142, loss: 0.0149, recall: 0.5625, mrr: 0.4875, time: 0.057646751403808594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 155\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 155, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5803, time: 0.05558061599731445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 60\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 60, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5029, time: 0.0537111759185791\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 274\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 274, train loss: 0.0143, loss: 0.0147, recall: 0.5625, mrr: 0.5203, time: 0.06423330307006836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 292\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 292, train loss: 0.0143, loss: 0.0148, recall: 0.5885, mrr: 0.5603, time: 0.05669665336608887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 195, train loss: 0.0144, loss: 0.0145, recall: 0.7656, mrr: 0.7161, time: 0.040282487869262695\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 61\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 61, train loss: 0.0143, loss: 0.0141, recall: 0.7266, mrr: 0.7000, time: 0.04918074607849121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 290\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 290, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5657, time: 0.05762314796447754\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 156, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6450, time: 0.05469512939453125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 5, train loss: 0.0144, loss: 0.0144, recall: 0.6797, mrr: 0.6184, time: 0.05568337440490723\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 238, train loss: 0.0143, loss: 0.0144, recall: 0.6927, mrr: 0.6056, time: 0.053964853286743164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 66\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 66, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5624, time: 0.05559873580932617\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 12\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 12, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6660, time: 0.046083688735961914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 123\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 123, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.5559, time: 0.05429506301879883\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 88\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 88, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.5931, time: 0.05799245834350586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 2, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5961, time: 0.0591127872467041\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 21\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 21, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6754, time: 0.04951834678649902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 45\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 40\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 40, train loss: 0.0142, loss: 0.0143, recall: 0.7656, mrr: 0.6987, time: 0.05262279510498047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 279\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 45, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5794, time: 0.05118131637573242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 279, train loss: 0.0141, loss: 0.0146, recall: 0.7422, mrr: 0.6980, time: 0.060449838638305664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 140\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 140, train loss: 0.0142, loss: 0.0144, recall: 0.6354, mrr: 0.5954, time: 0.05410265922546387\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 165\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 165, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6354, time: 0.0488736629486084\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 177\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 177, train loss: 0.0144, loss: 0.0145, recall: 0.6797, mrr: 0.6344, time: 0.04651951789855957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 101\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 101, train loss: 0.0142, loss: 0.0147, recall: 0.6328, mrr: 0.5452, time: 0.05781245231628418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 240\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 240, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.6281, time: 0.057470083236694336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 152, train loss: 0.0144, loss: 0.0147, recall: 0.5859, mrr: 0.5428, time: 0.0558476448059082\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 250\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 250, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5544, time: 0.05842423439025879\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 191, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6223, time: 0.05791664123535156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 113, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.6077, time: 0.05721139907836914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 224\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 224, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.4901, time: 0.05689287185668945\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 293, train loss: 0.0143, loss: 0.0144, recall: 0.6667, mrr: 0.6050, time: 0.057970285415649414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 194\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 194, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.5712, time: 0.05113697052001953\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 296\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 296, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.6305, time: 0.052901268005371094\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 91\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 91, train loss: 0.0143, loss: 0.0147, recall: 0.6615, mrr: 0.5559, time: 0.0589599609375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 9\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 9, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.6510, time: 0.055048227310180664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 54\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 54, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5662, time: 0.05705547332763672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 230\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 230, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5440, time: 0.055606842041015625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 276\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 276, train loss: 0.0144, loss: 0.0146, recall: 0.6302, mrr: 0.5547, time: 0.06222939491271973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 131\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 131, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.7017, time: 0.04630088806152344\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 128\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 128, train loss: 0.0143, loss: 0.0146, recall: 0.6328, mrr: 0.5388, time: 0.052754878997802734\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 173\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 173, train loss: 0.0142, loss: 0.0148, recall: 0.6562, mrr: 0.5505, time: 0.05254483222961426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 13:20:11,514 | server.py:281 | fit_round received 297 results and 3 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 295\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 134\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 134, train loss: 0.0143, loss: 0.0145, recall: 0.6354, mrr: 0.5526, time: 0.056313276290893555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 295, train loss: 0.0143, loss: 0.0145, recall: 0.6510, mrr: 0.5953, time: 0.0575098991394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 13:20:11,968 | server.py:215 | evaluate_round: strategy sampled 150 clients (out of 300)\n",
      "DEBUG flower 2022-06-17 13:22:20,172 | server.py:227 | evaluate_round received 149 results and 1 failures\n",
      "DEBUG flower 2022-06-17 13:22:20,415 | server.py:269 | fit_round: strategy sampled 300 clients (out of 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 78\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 189\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 231\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 128\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 178\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 212\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 250\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 38\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 245\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 84\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 149\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 97\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 280\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 128, train loss: 0.0143, loss: 0.0146, recall: 0.6328, mrr: 0.5388, time: 0.16742587089538574\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 178, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6190, time: 0.1501331329345703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 121, train loss: 0.0144, loss: 0.0142, recall: 0.7500, mrr: 0.7164, time: 0.15082740783691406\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 212, train loss: 0.0142, loss: 0.0147, recall: 0.5938, mrr: 0.5688, time: 0.17097759246826172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 38, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6398, time: 0.17156744003295898\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 149, train loss: 0.0141, loss: 0.0144, recall: 0.6953, mrr: 0.6029, time: 0.1732463836669922\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 245, train loss: 0.0143, loss: 0.0143, recall: 0.6484, mrr: 0.6020, time: 0.1872103214263916\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 78, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5217, time: 0.17064237594604492\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 189, train loss: 0.0143, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.20873427391052246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 160\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 231, train loss: 0.0143, loss: 0.0147, recall: 0.5885, mrr: 0.4687, time: 0.2020549774169922\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 273, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5653, time: 0.16766953468322754\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 250, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5544, time: 0.17831707000732422\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 84, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5408, time: 0.18462443351745605\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 97, train loss: 0.0144, loss: 0.0144, recall: 0.6510, mrr: 0.6369, time: 0.17278480529785156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 280, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6083, time: 0.17803239822387695\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 160, train loss: 0.0143, loss: 0.0146, recall: 0.6641, mrr: 0.6146, time: 0.06259536743164062\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 54\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 131\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 93\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 59\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 151\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 60\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 256\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 25\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 224\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 296\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 112, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6375, time: 0.16115236282348633\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 131, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.7017, time: 0.11058163642883301\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 99\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 93, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5674, time: 0.16022944450378418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 82\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 151, train loss: 0.0142, loss: 0.0144, recall: 0.6953, mrr: 0.6646, time: 0.14671540260314941\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 60, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5029, time: 0.13546061515808105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 256, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.6309, time: 0.1399974822998047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 25, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.6276, time: 0.14825177192687988\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 54, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5662, time: 0.15906786918640137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 224, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.4901, time: 0.15799188613891602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 99, train loss: 0.0141, loss: 0.0142, recall: 0.6797, mrr: 0.6686, time: 0.1469132900238037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 59, train loss: 0.0142, loss: 0.0145, recall: 0.6094, mrr: 0.6016, time: 0.15203619003295898\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 297, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.6217, time: 0.15199804306030273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 10, train loss: 0.0142, loss: 0.0142, recall: 0.7344, mrr: 0.6068, time: 0.14467692375183105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 296, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.6305, time: 0.17005467414855957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 140\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 180\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 86\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 174\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 150\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 287\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 159\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 271\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 199\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 180, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.6810, time: 0.11500763893127441\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 86, train loss: 0.0143, loss: 0.0146, recall: 0.5990, mrr: 0.5689, time: 0.17240500450134277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 153\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 174, train loss: 0.0142, loss: 0.0146, recall: 0.6016, mrr: 0.5602, time: 0.12401962280273438\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 140, train loss: 0.0142, loss: 0.0144, recall: 0.6354, mrr: 0.5954, time: 0.12999629974365234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 210\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 50\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 117, train loss: 0.0143, loss: 0.0147, recall: 0.6484, mrr: 0.5910, time: 0.14137887954711914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 278\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 153, train loss: 0.0143, loss: 0.0146, recall: 0.7188, mrr: 0.6615, time: 0.12952256202697754\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 150, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6303, time: 0.15474700927734375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 287, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5501, time: 0.1447460651397705\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 50, train loss: 0.0142, loss: 0.0147, recall: 0.6094, mrr: 0.5639, time: 0.1398618221282959\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 159, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.5677, time: 0.15990686416625977\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 271, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5854, time: 0.14171957969665527\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 199, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.5859, time: 0.23194575309753418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 68\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 3, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5861, time: 0.14192771911621094\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 210, train loss: 0.0142, loss: 0.0147, recall: 0.5417, mrr: 0.5115, time: 0.1476268768310547\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 278, train loss: 0.0144, loss: 0.0146, recall: 0.5781, mrr: 0.5431, time: 0.15062355995178223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 68, train loss: 0.0141, loss: 0.0145, recall: 0.6250, mrr: 0.5677, time: 0.11493921279907227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 83\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 100\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 165\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 40\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 87\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 80\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 182\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 110\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 55\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 79\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 71\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 165, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6354, time: 0.11720752716064453\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 40, train loss: 0.0142, loss: 0.0143, recall: 0.7656, mrr: 0.6987, time: 0.1225283145904541\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 80, train loss: 0.0143, loss: 0.0146, recall: 0.6615, mrr: 0.5911, time: 0.1475508213043213\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 87, train loss: 0.0143, loss: 0.0144, recall: 0.6797, mrr: 0.6105, time: 0.16132354736328125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 79, train loss: 0.0144, loss: 0.0142, recall: 0.7031, mrr: 0.6241, time: 0.16808199882507324\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 83, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4795, time: 0.142348051071167\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 100, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6320, time: 0.16531920433044434\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 71, train loss: 0.0143, loss: 0.0146, recall: 0.6354, mrr: 0.5727, time: 0.17264342308044434\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 277, train loss: 0.0144, loss: 0.0148, recall: 0.5469, mrr: 0.4754, time: 0.16437911987304688\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 182, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5159, time: 0.13544869422912598\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 110, train loss: 0.0145, loss: 0.0146, recall: 0.6172, mrr: 0.5598, time: 0.19191813468933105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 55, train loss: 0.0145, loss: 0.0144, recall: 0.6719, mrr: 0.5973, time: 0.17708635330200195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 94\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 67\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 2, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5961, time: 0.12774276733398438\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 94, train loss: 0.0142, loss: 0.0145, recall: 0.7031, mrr: 0.6829, time: 0.0895993709564209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 23\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 23, train loss: 0.0143, loss: 0.0144, recall: 0.6250, mrr: 0.5845, time: 0.06968331336975098\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 76\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 201\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 67, train loss: 0.0143, loss: 0.0141, recall: 0.7891, mrr: 0.7600, time: 0.1168978214263916\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 156, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6450, time: 0.06407690048217773\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 232\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 232, train loss: 0.0144, loss: 0.0150, recall: 0.5781, mrr: 0.4168, time: 0.08339309692382812\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 63\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 63, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6448, time: 0.06906437873840332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 76, train loss: 0.0144, loss: 0.0147, recall: 0.6146, mrr: 0.5184, time: 0.10357785224914551\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 201, train loss: 0.0144, loss: 0.0144, recall: 0.6562, mrr: 0.6167, time: 0.07215094566345215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 143\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 143, train loss: 0.0144, loss: 0.0150, recall: 0.5312, mrr: 0.4944, time: 0.06486296653747559\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 257\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 257, train loss: 0.0142, loss: 0.0144, recall: 0.7344, mrr: 0.5729, time: 0.06251287460327148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 161\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 161, train loss: 0.0142, loss: 0.0149, recall: 0.4844, mrr: 0.4410, time: 0.07130217552185059\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 30\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 30, train loss: 0.0143, loss: 0.0146, recall: 0.5859, mrr: 0.5716, time: 0.0874474048614502\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 120\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 120, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5417, time: 0.06788778305053711\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 194\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 66\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 286\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 286, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5820, time: 0.06311702728271484\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 124\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 124, train loss: 0.0143, loss: 0.0144, recall: 0.7266, mrr: 0.6259, time: 0.05777621269226074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 194, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.5712, time: 0.07096433639526367\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 66, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5624, time: 0.07190942764282227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 207, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6630, time: 0.07225751876831055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 11\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 11, train loss: 0.0145, loss: 0.0146, recall: 0.5703, mrr: 0.5253, time: 0.054941654205322266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 233\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 205\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 81\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 230\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 230, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5440, time: 0.0749053955078125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 37\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 37, train loss: 0.0144, loss: 0.0147, recall: 0.6133, mrr: 0.5169, time: 0.07668614387512207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 211, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.5194, time: 0.08477377891540527\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 233, train loss: 0.0144, loss: 0.0146, recall: 0.6875, mrr: 0.6099, time: 0.09060311317443848\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 0, train loss: 0.0139, loss: 0.0152, recall: 0.5469, mrr: 0.3775, time: 0.08825540542602539\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 205, train loss: 0.0142, loss: 0.0144, recall: 0.7578, mrr: 0.6117, time: 0.07498288154602051\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 81, train loss: 0.0144, loss: 0.0146, recall: 0.5469, mrr: 0.5155, time: 0.08829426765441895\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 96\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 241\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 197\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 19\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 88\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 265\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 44\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 73\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 70\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 61\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 144\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 265, train loss: 0.0144, loss: 0.0147, recall: 0.5729, mrr: 0.5403, time: 0.1190176010131836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 73, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4895, time: 0.17804980278015137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 96, train loss: 0.0142, loss: 0.0148, recall: 0.5938, mrr: 0.5070, time: 0.17904949188232422\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 241, train loss: 0.0142, loss: 0.0147, recall: 0.6641, mrr: 0.5533, time: 0.1656649112701416\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 197, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6350, time: 0.1607370376586914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 19, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5641, time: 0.1686849594116211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 88, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.5931, time: 0.17306756973266602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 172, train loss: 0.0143, loss: 0.0144, recall: 0.6719, mrr: 0.6219, time: 0.1602783203125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 44, train loss: 0.0142, loss: 0.0143, recall: 0.6875, mrr: 0.6382, time: 0.16274309158325195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 195, train loss: 0.0144, loss: 0.0145, recall: 0.7656, mrr: 0.7161, time: 0.12490987777709961\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 70, train loss: 0.0142, loss: 0.0144, recall: 0.6302, mrr: 0.5645, time: 0.1597292423248291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 61, train loss: 0.0143, loss: 0.0141, recall: 0.7266, mrr: 0.7000, time: 0.15571355819702148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 144, train loss: 0.0144, loss: 0.0145, recall: 0.6979, mrr: 0.6681, time: 0.16955304145812988\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 281, train loss: 0.0143, loss: 0.0143, recall: 0.7578, mrr: 0.7477, time: 0.1703357696533203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 270\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 295\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 107\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 264\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 253\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 62\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 270, train loss: 0.0143, loss: 0.0142, recall: 0.7031, mrr: 0.6734, time: 0.07494330406188965\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 295, train loss: 0.0143, loss: 0.0145, recall: 0.6510, mrr: 0.5953, time: 0.08113622665405273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 107, train loss: 0.0143, loss: 0.0146, recall: 0.6289, mrr: 0.5212, time: 0.08689594268798828\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 264, train loss: 0.0143, loss: 0.0143, recall: 0.7500, mrr: 0.6477, time: 0.08239388465881348\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 253, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6102, time: 0.0811002254486084\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 62, train loss: 0.0143, loss: 0.0145, recall: 0.6797, mrr: 0.6160, time: 0.07730412483215332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 53\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 53, train loss: 0.0144, loss: 0.0146, recall: 0.6615, mrr: 0.5601, time: 0.06345772743225098\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 158\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 158, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6100, time: 0.058614253997802734\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 291, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6156, time: 0.07459568977355957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 266, train loss: 0.0142, loss: 0.0143, recall: 0.7344, mrr: 0.6526, time: 0.061713218688964844\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 154\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 147\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 108\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 167\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 104\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 46\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 57\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 154, train loss: 0.0143, loss: 0.0147, recall: 0.5469, mrr: 0.5172, time: 0.10645341873168945\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 147, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6409, time: 0.13157272338867188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 108, train loss: 0.0143, loss: 0.0145, recall: 0.6302, mrr: 0.5568, time: 0.18098998069763184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 167, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6945, time: 0.11463022232055664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 104, train loss: 0.0143, loss: 0.0147, recall: 0.5781, mrr: 0.4836, time: 0.1224365234375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 46, train loss: 0.0142, loss: 0.0143, recall: 0.7109, mrr: 0.6641, time: 0.13028264045715332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 57, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5316, time: 0.12662386894226074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 22\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 22, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6507, time: 0.0740060806274414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 185, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.6393, time: 0.0772397518157959\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 243\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 243, train loss: 0.0143, loss: 0.0145, recall: 0.7109, mrr: 0.6596, time: 0.0811758041381836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 13\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 72\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 72, train loss: 0.0143, loss: 0.0148, recall: 0.5938, mrr: 0.5529, time: 0.07935857772827148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 289, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6410, time: 0.06966924667358398\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 13, train loss: 0.0142, loss: 0.0145, recall: 0.6562, mrr: 0.5214, time: 0.083648681640625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 203, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.5908, time: 0.059712886810302734\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 109\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 109, train loss: 0.0144, loss: 0.0146, recall: 0.5898, mrr: 0.5479, time: 0.08066654205322266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 246, train loss: 0.0143, loss: 0.0146, recall: 0.7109, mrr: 0.5932, time: 0.05724620819091797\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 192\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 274\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 74\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 20\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 29\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 28\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 279\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 251\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 263\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 192, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6246, time: 0.12643885612487793\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 274, train loss: 0.0143, loss: 0.0147, recall: 0.5625, mrr: 0.5203, time: 0.10997223854064941\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 74, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5390, time: 0.1325678825378418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 20, train loss: 0.0144, loss: 0.0146, recall: 0.6458, mrr: 0.5633, time: 0.1408519744873047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 29, train loss: 0.0145, loss: 0.0146, recall: 0.5781, mrr: 0.5310, time: 0.07747554779052734\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 263, train loss: 0.0143, loss: 0.0147, recall: 0.6094, mrr: 0.5726, time: 0.10389518737792969\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 28, train loss: 0.0143, loss: 0.0143, recall: 0.7344, mrr: 0.7188, time: 0.11893200874328613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 251, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6435, time: 0.12607765197753906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 188, train loss: 0.0144, loss: 0.0149, recall: 0.5000, mrr: 0.4807, time: 0.13540124893188477\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 5, train loss: 0.0144, loss: 0.0144, recall: 0.6797, mrr: 0.6184, time: 0.13196134567260742\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 279, train loss: 0.0141, loss: 0.0146, recall: 0.7422, mrr: 0.6980, time: 0.11217737197875977\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 141\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 227, train loss: 0.0143, loss: 0.0147, recall: 0.6172, mrr: 0.6003, time: 0.08005070686340332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 141, train loss: 0.0143, loss: 0.0142, recall: 0.7109, mrr: 0.6385, time: 0.06643986701965332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 127\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 127, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.06296873092651367\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 168\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 168, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5689, time: 0.059020042419433594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 33\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 226\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 226, train loss: 0.0143, loss: 0.0146, recall: 0.5625, mrr: 0.5076, time: 0.06097912788391113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 33, train loss: 0.0144, loss: 0.0146, recall: 0.6823, mrr: 0.6515, time: 0.0699152946472168\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 238, train loss: 0.0143, loss: 0.0144, recall: 0.6927, mrr: 0.6056, time: 0.058000802993774414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 15\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 15, train loss: 0.0142, loss: 0.0145, recall: 0.6641, mrr: 0.5732, time: 0.06455373764038086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 163\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 163, train loss: 0.0143, loss: 0.0147, recall: 0.6667, mrr: 0.4780, time: 0.06379818916320801\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 135\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 135, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5501, time: 0.06294417381286621\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 32\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 32, train loss: 0.0143, loss: 0.0142, recall: 0.7188, mrr: 0.6708, time: 0.08286404609680176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 36\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 261\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 98\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 130\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 237\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 292\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 130, train loss: 0.0143, loss: 0.0142, recall: 0.6953, mrr: 0.6673, time: 0.08006548881530762\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 91\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 175\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 261, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6956, time: 0.20624709129333496\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 114\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 237, train loss: 0.0142, loss: 0.0142, recall: 0.6719, mrr: 0.6719, time: 0.07321643829345703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 102\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 292, train loss: 0.0143, loss: 0.0148, recall: 0.5885, mrr: 0.5603, time: 0.0843048095703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 91, train loss: 0.0143, loss: 0.0147, recall: 0.6615, mrr: 0.5559, time: 0.08449435234069824\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 175, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6335, time: 0.07017207145690918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 114, train loss: 0.0144, loss: 0.0147, recall: 0.6250, mrr: 0.5761, time: 0.09632086753845215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 102, train loss: 0.0144, loss: 0.0145, recall: 0.6615, mrr: 0.6044, time: 0.0913083553314209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 288\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 288, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.06552767753601074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 36, train loss: 0.0143, loss: 0.0144, recall: 0.7422, mrr: 0.6885, time: 0.7358818054199219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 98, train loss: 0.0144, loss: 0.0146, recall: 0.6172, mrr: 0.5344, time: 0.7369883060455322\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 225\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 18\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 123\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 17\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 225, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6697, time: 0.06693434715270996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 18, train loss: 0.0143, loss: 0.0146, recall: 0.6302, mrr: 0.5913, time: 0.07202935218811035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 285, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6250, time: 0.06508994102478027\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 123, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.5559, time: 0.06302452087402344\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 17, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.5509, time: 0.06399297714233398\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 181\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 235\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 139\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 47\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 157\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 181, train loss: 0.0142, loss: 0.0146, recall: 0.6719, mrr: 0.6237, time: 0.10123181343078613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 95\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 235, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5985, time: 0.10622286796569824\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 204\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 204, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.6099, time: 0.08103632926940918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 139, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5710, time: 0.10755300521850586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 47, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.6680, time: 0.10366487503051758\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 157, train loss: 0.0143, loss: 0.0144, recall: 0.6406, mrr: 0.6043, time: 0.1106560230255127\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 248\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 95, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5624, time: 0.0930025577545166\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 248, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6302, time: 0.10112619400024414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 177\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 177, train loss: 0.0144, loss: 0.0145, recall: 0.6797, mrr: 0.6344, time: 0.05604672431945801\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 134\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 134, train loss: 0.0143, loss: 0.0145, recall: 0.6354, mrr: 0.5526, time: 0.0653533935546875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 268\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 171\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 171, train loss: 0.0144, loss: 0.0144, recall: 0.6979, mrr: 0.6311, time: 0.07034134864807129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 148, train loss: 0.0144, loss: 0.0144, recall: 0.7083, mrr: 0.6253, time: 0.07187676429748535\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 34\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 26\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 268, train loss: 0.0143, loss: 0.0146, recall: 0.6172, mrr: 0.5504, time: 0.07521700859069824\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 129, train loss: 0.0142, loss: 0.0142, recall: 0.7734, mrr: 0.7216, time: 0.052092790603637695\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 34, train loss: 0.0144, loss: 0.0145, recall: 0.6406, mrr: 0.5938, time: 0.0715019702911377\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 26, train loss: 0.0143, loss: 0.0144, recall: 0.5938, mrr: 0.5749, time: 0.06639242172241211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 299\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 119\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 119, train loss: 0.0142, loss: 0.0144, recall: 0.7656, mrr: 0.7500, time: 0.05743718147277832\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 234, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6891, time: 0.06949353218078613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m   out=out, **kwargs)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m   ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 187\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 187, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6389, time: 0.0726475715637207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 255\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 255, train loss: 0.0142, loss: 0.0146, recall: 0.6328, mrr: 0.5983, time: 0.05841875076293945\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 222, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6531, time: 0.06215095520019531\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 164, train loss: 0.0144, loss: 0.0146, recall: 0.5859, mrr: 0.5257, time: 0.06441950798034668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 249\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 249, train loss: 0.0144, loss: 0.0148, recall: 0.5859, mrr: 0.5083, time: 0.05941605567932129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 7\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 170\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 193\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 122\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 21\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 21, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6754, time: 0.05588674545288086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 7, train loss: 0.0144, loss: 0.0146, recall: 0.6250, mrr: 0.6038, time: 0.0708308219909668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 170, train loss: 0.0143, loss: 0.0146, recall: 0.6094, mrr: 0.5098, time: 0.0726923942565918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 179\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 179, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.6276, time: 0.05192089080810547\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 193, train loss: 0.0144, loss: 0.0145, recall: 0.6042, mrr: 0.5546, time: 0.0684354305267334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 122, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6359, time: 0.0630333423614502\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 259, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6214, time: 0.06399178504943848\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 183\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 214\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 282\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 282, train loss: 0.0143, loss: 0.0145, recall: 0.8281, mrr: 0.6672, time: 0.06894350051879883\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 146\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 284\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 116\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 183, train loss: 0.0144, loss: 0.0149, recall: 0.5781, mrr: 0.4992, time: 0.07889914512634277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 115\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 115, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.6428, time: 0.09014678001403809\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 284, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.5844, time: 0.07736563682556152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 247\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 247, train loss: 0.0144, loss: 0.0147, recall: 0.7031, mrr: 0.5725, time: 0.07960748672485352\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 214, train loss: 0.0144, loss: 0.0143, recall: 0.7734, mrr: 0.6698, time: 0.08725881576538086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 103\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 146, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.5919, time: 0.08501148223876953\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 116, train loss: 0.0144, loss: 0.0148, recall: 0.5833, mrr: 0.5042, time: 0.08142423629760742\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 103, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.5661, time: 0.0782170295715332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 217\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 294\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 229\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 198\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 252\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 217, train loss: 0.0142, loss: 0.0147, recall: 0.6016, mrr: 0.5534, time: 0.07335948944091797\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 294, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.5938, time: 0.0731821060180664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 125, train loss: 0.0144, loss: 0.0147, recall: 0.6328, mrr: 0.5630, time: 0.07514619827270508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 229, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5677, time: 0.0930318832397461\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 198, train loss: 0.0144, loss: 0.0143, recall: 0.6875, mrr: 0.6510, time: 0.07493734359741211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 252, train loss: 0.0144, loss: 0.0142, recall: 0.6797, mrr: 0.6452, time: 0.08249330520629883\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 64\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 101\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 169\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 240\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 190\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 92\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 64, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5874, time: 0.12281584739685059\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 101, train loss: 0.0142, loss: 0.0147, recall: 0.6328, mrr: 0.5452, time: 0.09132099151611328\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 126\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 200\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 58\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 169, train loss: 0.0143, loss: 0.0146, recall: 0.6042, mrr: 0.5390, time: 0.13371562957763672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 240, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.6281, time: 0.15570974349975586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 190, train loss: 0.0143, loss: 0.0149, recall: 0.5885, mrr: 0.4434, time: 0.14986634254455566\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 209, train loss: 0.0144, loss: 0.0144, recall: 0.6953, mrr: 0.6797, time: 0.15071320533752441\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 92, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6057, time: 0.1040334701538086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 126, train loss: 0.0143, loss: 0.0141, recall: 0.7734, mrr: 0.6767, time: 0.14985013008117676\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 105, train loss: 0.0144, loss: 0.0147, recall: 0.5391, mrr: 0.5100, time: 0.14287042617797852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 200, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5898, time: 0.14531612396240234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 58, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6246, time: 0.13557791709899902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 216\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 216, train loss: 0.0143, loss: 0.0141, recall: 0.7500, mrr: 0.7083, time: 0.06495046615600586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 254, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.5905, time: 0.11015820503234863\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 45\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 45, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5794, time: 0.057694435119628906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 208\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 208, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5952, time: 0.05688834190368652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 272\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 272, train loss: 0.0143, loss: 0.0143, recall: 0.6667, mrr: 0.6201, time: 0.07343149185180664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 69\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 69, train loss: 0.0143, loss: 0.0143, recall: 0.6719, mrr: 0.6380, time: 0.06268477439880371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 77\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 77, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.5484, time: 0.06964755058288574\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 220\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 220, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6339, time: 0.06940054893493652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 56\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 1, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.5926, time: 0.06715750694274902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 56, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6589, time: 0.06280827522277832\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 276\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 276, train loss: 0.0144, loss: 0.0146, recall: 0.6302, mrr: 0.5547, time: 0.06838536262512207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 155\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 39\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 8\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 52\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 9\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 75\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 132\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 173\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 52, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6288, time: 0.13465189933776855\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 262, train loss: 0.0143, loss: 0.0145, recall: 0.6250, mrr: 0.6031, time: 0.10272884368896484\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 155, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5803, time: 0.19235873222351074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 191, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6223, time: 0.16959500312805176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 39, train loss: 0.0142, loss: 0.0146, recall: 0.6250, mrr: 0.5569, time: 0.17602968215942383\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 6, train loss: 0.0142, loss: 0.0143, recall: 0.6562, mrr: 0.6099, time: 0.16570687294006348\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 133, train loss: 0.0143, loss: 0.0144, recall: 0.7396, mrr: 0.6594, time: 0.18335747718811035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 8, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6038, time: 0.19394445419311523\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 145, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6725, time: 0.16620779037475586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 215, train loss: 0.0144, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.15877294540405273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 9, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.6510, time: 0.1685495376586914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 184, train loss: 0.0143, loss: 0.0145, recall: 0.7266, mrr: 0.6857, time: 0.19271039962768555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 132, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6432, time: 0.16192388534545898\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 173, train loss: 0.0142, loss: 0.0148, recall: 0.6562, mrr: 0.5505, time: 0.16973280906677246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 269\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 166\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 138\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 142\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 16\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 49\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 42\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 136\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 137, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5836, time: 0.12528157234191895\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 27\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 106\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 258, train loss: 0.0144, loss: 0.0147, recall: 0.5781, mrr: 0.5617, time: 0.16162919998168945\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 269, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6773, time: 0.17254209518432617\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 27, train loss: 0.0144, loss: 0.0142, recall: 0.7812, mrr: 0.6984, time: 0.13230681419372559\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 223, train loss: 0.0144, loss: 0.0144, recall: 0.6250, mrr: 0.5803, time: 0.17813920974731445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 166, train loss: 0.0142, loss: 0.0149, recall: 0.5547, mrr: 0.4693, time: 0.15577054023742676\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 136, train loss: 0.0143, loss: 0.0146, recall: 0.5469, mrr: 0.5071, time: 0.16585636138916016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 138, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.6432, time: 0.16509199142456055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 142, train loss: 0.0144, loss: 0.0144, recall: 0.7031, mrr: 0.6676, time: 0.16733145713806152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 16, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5807, time: 0.17432713508605957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 111, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6393, time: 0.17462515830993652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 106, train loss: 0.0142, loss: 0.0149, recall: 0.5625, mrr: 0.4875, time: 0.1721339225769043\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 242, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5234, time: 0.1643238067626953\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 49, train loss: 0.0144, loss: 0.0142, recall: 0.6927, mrr: 0.6710, time: 0.16540074348449707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 42, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.6263, time: 0.15517544746398926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 176, train loss: 0.0143, loss: 0.0141, recall: 0.7812, mrr: 0.7141, time: 0.04734444618225098\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 202\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 202, train loss: 0.0143, loss: 0.0146, recall: 0.6953, mrr: 0.6698, time: 0.05575752258300781\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 298\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 298, train loss: 0.0142, loss: 0.0144, recall: 0.7083, mrr: 0.5721, time: 0.056995391845703125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 12\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 12, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6660, time: 0.045053720474243164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 14\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 14, train loss: 0.0143, loss: 0.0144, recall: 0.6510, mrr: 0.5925, time: 0.05428004264831543\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 118\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 118, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6599, time: 0.046053171157836914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 90\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 90, train loss: 0.0144, loss: 0.0145, recall: 0.6328, mrr: 0.5740, time: 0.0641636848449707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 293, train loss: 0.0143, loss: 0.0144, recall: 0.6667, mrr: 0.6050, time: 0.05659985542297363\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 221\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 221, train loss: 0.0143, loss: 0.0144, recall: 0.7135, mrr: 0.6486, time: 0.19289493560791016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 228\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 228, train loss: 0.0143, loss: 0.0146, recall: 0.5781, mrr: 0.5052, time: 0.057315826416015625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 51\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 51, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5901, time: 0.05969524383544922\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 290\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 290, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5657, time: 0.05639004707336426\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 4\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 4, train loss: 0.0143, loss: 0.0143, recall: 0.6953, mrr: 0.6305, time: 0.057944536209106445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 236\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 236, train loss: 0.0144, loss: 0.0142, recall: 0.6719, mrr: 0.6602, time: 0.05446648597717285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 85\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 85, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.7047, time: 0.0599672794342041\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 275\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 275, train loss: 0.0142, loss: 0.0146, recall: 0.6562, mrr: 0.6189, time: 0.05940699577331543\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 218\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 218, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6424, time: 0.06257295608520508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 196\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 196, train loss: 0.0144, loss: 0.0145, recall: 0.6458, mrr: 0.6007, time: 0.0486299991607666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 152, train loss: 0.0144, loss: 0.0147, recall: 0.5859, mrr: 0.5428, time: 0.057599782943725586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 244\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 244, train loss: 0.0142, loss: 0.0144, recall: 0.6458, mrr: 0.5933, time: 0.05560946464538574\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 113, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.6077, time: 0.05975818634033203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 219, train loss: 0.0142, loss: 0.0148, recall: 0.6406, mrr: 0.5796, time: 0.05915355682373047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 283\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 283, train loss: 0.0144, loss: 0.0144, recall: 0.6172, mrr: 0.5931, time: 0.050827741622924805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 31\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 31, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6615, time: 0.0562741756439209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 162\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 162, train loss: 0.0144, loss: 0.0145, recall: 0.5938, mrr: 0.5670, time: 0.0568232536315918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 24\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 24, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.5940, time: 0.05179142951965332\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 186, train loss: 0.0143, loss: 0.0144, recall: 0.6992, mrr: 0.5725, time: 0.06549429893493652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 48\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 48, train loss: 0.0141, loss: 0.0144, recall: 0.6797, mrr: 0.6253, time: 0.05312037467956543\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 206\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 206, train loss: 0.0143, loss: 0.0145, recall: 0.6042, mrr: 0.5494, time: 0.05573010444641113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 89\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 89, train loss: 0.0143, loss: 0.0149, recall: 0.5729, mrr: 0.5129, time: 0.05976104736328125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 213\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 213, train loss: 0.0144, loss: 0.0148, recall: 0.5781, mrr: 0.4879, time: 0.05271649360656738\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 35\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 35, train loss: 0.0143, loss: 0.0143, recall: 0.6823, mrr: 0.6280, time: 0.05984950065612793\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 267\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 267, train loss: 0.0142, loss: 0.0146, recall: 0.5833, mrr: 0.5612, time: 0.05278801918029785\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 65\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 65, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6094, time: 0.052866220474243164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 43\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 43, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6523, time: 0.05247783660888672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 41\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 41, train loss: 0.0143, loss: 0.0146, recall: 0.7656, mrr: 0.7190, time: 0.07051968574523926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 239\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 239, train loss: 0.0143, loss: 0.0139, recall: 0.8281, mrr: 0.7766, time: 0.055927276611328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 13:33:16,371 | server.py:281 | fit_round received 297 results and 3 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 260\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 260, train loss: 0.0143, loss: 0.0142, recall: 0.7500, mrr: 0.7233, time: 0.049485206604003906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 13:33:16,839 | server.py:215 | evaluate_round: strategy sampled 150 clients (out of 300)\n",
      "DEBUG flower 2022-06-17 13:35:49,964 | server.py:227 | evaluate_round received 150 results and 0 failures\n",
      "DEBUG flower 2022-06-17 13:35:50,098 | server.py:269 | fit_round: strategy sampled 300 clients (out of 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 192\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 128\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 94\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 189\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 34\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 131\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 205\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 167\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 16\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 68\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 213\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 68, train loss: 0.0141, loss: 0.0145, recall: 0.6250, mrr: 0.5677, time: 0.27065372467041016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 213, train loss: 0.0144, loss: 0.0148, recall: 0.5781, mrr: 0.4879, time: 0.2768876552581787\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 192, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6246, time: 0.3322446346282959\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 128, train loss: 0.0143, loss: 0.0146, recall: 0.6328, mrr: 0.5388, time: 0.3590877056121826\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 94, train loss: 0.0142, loss: 0.0145, recall: 0.7031, mrr: 0.6829, time: 0.3152785301208496\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 189, train loss: 0.0143, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.30365467071533203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 34, train loss: 0.0144, loss: 0.0145, recall: 0.6406, mrr: 0.5938, time: 0.3538320064544678\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 131, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.7017, time: 0.3193237781524658\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 163\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 143\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 205, train loss: 0.0142, loss: 0.0144, recall: 0.7578, mrr: 0.6117, time: 0.32846879959106445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 167, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6945, time: 0.28648853302001953\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch #\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 16, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5807, time: 0.2926673889160156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 223, train loss: 0.0144, loss: 0.0144, recall: 0.6250, mrr: 0.5803, time: 0.30696773529052734\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 159\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m  80\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 166\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 219\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 159, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.5677, time: 0.1761016845703125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 47\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 163, train loss: 0.0143, loss: 0.0147, recall: 0.6667, mrr: 0.4780, time: 0.1605384349822998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 143, train loss: 0.0144, loss: 0.0150, recall: 0.5312, mrr: 0.4944, time: 0.17496752738952637\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 80, train loss: 0.0143, loss: 0.0146, recall: 0.6615, mrr: 0.5911, time: 0.22070097923278809\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 166, train loss: 0.0142, loss: 0.0149, recall: 0.5547, mrr: 0.4693, time: 0.12441658973693848\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 21\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 49\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 219, train loss: 0.0142, loss: 0.0148, recall: 0.6406, mrr: 0.5796, time: 0.1434788703918457\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 58\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 287\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 21, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6754, time: 0.13225960731506348\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 175\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 93\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 47, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.6680, time: 0.1732168197631836\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 49, train loss: 0.0144, loss: 0.0142, recall: 0.6927, mrr: 0.6710, time: 0.12337183952331543\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 40\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 240\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 202\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 58, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6246, time: 0.1176605224609375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 93, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5674, time: 0.15486788749694824\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 146\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 40, train loss: 0.0142, loss: 0.0143, recall: 0.7656, mrr: 0.6987, time: 0.12119293212890625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 175, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6335, time: 0.128157377243042\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 44\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 202, train loss: 0.0143, loss: 0.0146, recall: 0.6953, mrr: 0.6698, time: 0.11191725730895996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 287, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5501, time: 0.1566612720489502\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 146, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.5919, time: 0.1429920196533203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 216\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 216, train loss: 0.0143, loss: 0.0141, recall: 0.7500, mrr: 0.7083, time: 0.0989832878112793\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 44, train loss: 0.0142, loss: 0.0143, recall: 0.6875, mrr: 0.6382, time: 0.10394120216369629\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 97\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 240, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.6281, time: 0.1641390323638916\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 290\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 290, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5657, time: 0.07218408584594727\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 26\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 248\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 284\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 265\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 97, train loss: 0.0144, loss: 0.0144, recall: 0.6510, mrr: 0.6369, time: 0.09792947769165039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 26, train loss: 0.0143, loss: 0.0144, recall: 0.5938, mrr: 0.5749, time: 0.0666806697845459\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 248, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6302, time: 0.07979035377502441\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 284, train loss: 0.0143, loss: 0.0146, recall: 0.6484, mrr: 0.5844, time: 0.07007884979248047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 265, train loss: 0.0144, loss: 0.0147, recall: 0.5729, mrr: 0.5403, time: 0.07373356819152832\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 57\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 57, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5316, time: 0.06141090393066406\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 274\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 270\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 170\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 224\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 105\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 274, train loss: 0.0143, loss: 0.0147, recall: 0.5625, mrr: 0.5203, time: 0.08998727798461914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 270, train loss: 0.0143, loss: 0.0142, recall: 0.7031, mrr: 0.6734, time: 0.07244729995727539\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 170, train loss: 0.0143, loss: 0.0146, recall: 0.6094, mrr: 0.5098, time: 0.07526254653930664\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 224, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.4901, time: 0.07681679725646973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 105, train loss: 0.0144, loss: 0.0147, recall: 0.5391, mrr: 0.5100, time: 0.0853264331817627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 50\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 148, train loss: 0.0144, loss: 0.0144, recall: 0.7083, mrr: 0.6253, time: 0.3714451789855957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 267\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 267, train loss: 0.0142, loss: 0.0146, recall: 0.5833, mrr: 0.5612, time: 0.061885833740234375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 50, train loss: 0.0142, loss: 0.0147, recall: 0.6094, mrr: 0.5639, time: 0.3297388553619385\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 197\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 197, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6350, time: 0.08722400665283203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 2, train loss: 0.0144, loss: 0.0145, recall: 0.6354, mrr: 0.5961, time: 0.3827705383300781\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 118\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 23\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 271\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 282\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 118, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6599, time: 0.05568981170654297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 234\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 234, train loss: 0.0143, loss: 0.0144, recall: 0.7109, mrr: 0.6891, time: 0.08862519264221191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 271, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5854, time: 0.0643014907836914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 282, train loss: 0.0143, loss: 0.0145, recall: 0.8281, mrr: 0.6672, time: 0.06259942054748535\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 23, train loss: 0.0143, loss: 0.0144, recall: 0.6250, mrr: 0.5845, time: 0.13409805297851562\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 184, train loss: 0.0143, loss: 0.0145, recall: 0.7266, mrr: 0.6857, time: 0.07064151763916016\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 51\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 137\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 229\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 229, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5677, time: 0.07350897789001465\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 51, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5901, time: 0.12103486061096191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 137, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5836, time: 0.08412957191467285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 288\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 288, train loss: 0.0142, loss: 0.0146, recall: 0.6458, mrr: 0.5590, time: 0.07322931289672852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 227, train loss: 0.0143, loss: 0.0147, recall: 0.6172, mrr: 0.6003, time: 0.07335186004638672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 67\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 38\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 204\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 211, train loss: 0.0144, loss: 0.0146, recall: 0.5625, mrr: 0.5194, time: 0.07424116134643555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 204, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.6099, time: 0.06980681419372559\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 156, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6450, time: 0.0656580924987793\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 214\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 214, train loss: 0.0144, loss: 0.0143, recall: 0.7734, mrr: 0.6698, time: 0.0682225227355957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 67, train loss: 0.0143, loss: 0.0141, recall: 0.7891, mrr: 0.7600, time: 0.3366999626159668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 38, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6398, time: 0.1721949577331543\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 114\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 114, train loss: 0.0144, loss: 0.0147, recall: 0.6250, mrr: 0.5761, time: 0.08148312568664551\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 29\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 29, train loss: 0.0145, loss: 0.0146, recall: 0.5781, mrr: 0.5310, time: 0.07220005989074707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 45\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 5, train loss: 0.0144, loss: 0.0144, recall: 0.6797, mrr: 0.6184, time: 0.25019311904907227\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 45, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5794, time: 0.057227373123168945\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 228\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 85\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 24\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 228, train loss: 0.0143, loss: 0.0146, recall: 0.5781, mrr: 0.5052, time: 0.07562518119812012\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 85, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.7047, time: 0.07084202766418457\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 30\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 24, train loss: 0.0142, loss: 0.0145, recall: 0.6953, mrr: 0.5940, time: 0.8854207992553711\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 30, train loss: 0.0143, loss: 0.0146, recall: 0.5859, mrr: 0.5716, time: 0.865192174911499\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 141\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 141, train loss: 0.0143, loss: 0.0142, recall: 0.7109, mrr: 0.6385, time: 0.05468249320983887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 206\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 206, train loss: 0.0143, loss: 0.0145, recall: 0.6042, mrr: 0.5494, time: 0.3343067169189453\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 20\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 20, train loss: 0.0144, loss: 0.0146, recall: 0.6458, mrr: 0.5633, time: 0.08518218994140625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 144\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 59\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 59, train loss: 0.0142, loss: 0.0145, recall: 0.6094, mrr: 0.6016, time: 0.06283068656921387\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 203, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.5908, time: 0.07505226135253906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 153\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 6, train loss: 0.0142, loss: 0.0143, recall: 0.6562, mrr: 0.6099, time: 0.066680908203125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 144, train loss: 0.0144, loss: 0.0145, recall: 0.6979, mrr: 0.6681, time: 0.07872486114501953\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 153, train loss: 0.0143, loss: 0.0146, recall: 0.7188, mrr: 0.6615, time: 0.07306957244873047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 254, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.5905, time: 0.4888622760772705\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 19\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 176\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 151\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 19, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5641, time: 0.07152748107910156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 176, train loss: 0.0143, loss: 0.0141, recall: 0.7812, mrr: 0.7141, time: 0.05793118476867676\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 151, train loss: 0.0142, loss: 0.0144, recall: 0.6953, mrr: 0.6646, time: 0.07013964653015137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 101\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 136\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 136, train loss: 0.0143, loss: 0.0146, recall: 0.5469, mrr: 0.5071, time: 0.06375718116760254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 101, train loss: 0.0142, loss: 0.0147, recall: 0.6328, mrr: 0.5452, time: 0.08046388626098633\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 188, train loss: 0.0144, loss: 0.0149, recall: 0.5000, mrr: 0.4807, time: 0.07211470603942871\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 73\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 73, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4895, time: 0.08146905899047852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 231\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 231, train loss: 0.0143, loss: 0.0147, recall: 0.5885, mrr: 0.4687, time: 0.0715169906616211\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 41\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 0, train loss: 0.0139, loss: 0.0152, recall: 0.5469, mrr: 0.3775, time: 0.08088135719299316\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 130\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 130, train loss: 0.0143, loss: 0.0142, recall: 0.6953, mrr: 0.6673, time: 0.06414294242858887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 41, train loss: 0.0143, loss: 0.0146, recall: 0.7656, mrr: 0.7190, time: 0.06046342849731445\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 212\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 296\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 296, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.6305, time: 0.06403255462646484\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 212, train loss: 0.0142, loss: 0.0147, recall: 0.5938, mrr: 0.5688, time: 0.06375861167907715\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 237\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 237, train loss: 0.0142, loss: 0.0142, recall: 0.6719, mrr: 0.6719, time: 0.056302547454833984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 226\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 46\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 169\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 191\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 226, train loss: 0.0143, loss: 0.0146, recall: 0.5625, mrr: 0.5076, time: 0.07941341400146484\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 46, train loss: 0.0142, loss: 0.0143, recall: 0.7109, mrr: 0.6641, time: 0.07242226600646973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 119\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 119, train loss: 0.0142, loss: 0.0144, recall: 0.7656, mrr: 0.7500, time: 0.06038832664489746\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 169, train loss: 0.0143, loss: 0.0146, recall: 0.6042, mrr: 0.5390, time: 0.08624625205993652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 111, train loss: 0.0143, loss: 0.0143, recall: 0.6875, mrr: 0.6393, time: 0.08240652084350586\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 191, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6223, time: 0.09390592575073242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 242, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5234, time: 0.0856776237487793\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 210\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 174\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 174, train loss: 0.0142, loss: 0.0146, recall: 0.6016, mrr: 0.5602, time: 0.05129885673522949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 210, train loss: 0.0142, loss: 0.0147, recall: 0.5417, mrr: 0.5115, time: 0.0690312385559082\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 277, train loss: 0.0144, loss: 0.0148, recall: 0.5469, mrr: 0.4754, time: 0.07145071029663086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 61\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 61, train loss: 0.0143, loss: 0.0141, recall: 0.7266, mrr: 0.7000, time: 0.05556297302246094\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 110\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 13\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 13, train loss: 0.0142, loss: 0.0145, recall: 0.6562, mrr: 0.5214, time: 0.0632786750793457\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 180\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 180, train loss: 0.0143, loss: 0.0143, recall: 0.7188, mrr: 0.6810, time: 0.05129432678222656\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 110, train loss: 0.0145, loss: 0.0146, recall: 0.6172, mrr: 0.5598, time: 0.0800926685333252\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 293, train loss: 0.0143, loss: 0.0144, recall: 0.6667, mrr: 0.6050, time: 0.0671682357788086\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 149\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 149, train loss: 0.0141, loss: 0.0144, recall: 0.6953, mrr: 0.6029, time: 0.06194472312927246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 43\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 241\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 27\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 236\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 294\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 43, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6523, time: 0.08306312561035156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 241, train loss: 0.0142, loss: 0.0147, recall: 0.6641, mrr: 0.5533, time: 0.08785700798034668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 177\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 177, train loss: 0.0144, loss: 0.0145, recall: 0.6797, mrr: 0.6344, time: 0.06187558174133301\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 27, train loss: 0.0144, loss: 0.0142, recall: 0.7812, mrr: 0.6984, time: 0.07075858116149902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 236, train loss: 0.0144, loss: 0.0142, recall: 0.6719, mrr: 0.6602, time: 0.07912635803222656\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 294, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.5938, time: 0.07954192161560059\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 157\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 157, train loss: 0.0143, loss: 0.0144, recall: 0.6406, mrr: 0.6043, time: 0.07176566123962402\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 104\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 104, train loss: 0.0143, loss: 0.0147, recall: 0.5781, mrr: 0.4836, time: 0.06355404853820801\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 247\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 247, train loss: 0.0144, loss: 0.0147, recall: 0.7031, mrr: 0.5725, time: 0.05953574180603027\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 297, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.6217, time: 0.13005280494689941\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 48\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 48, train loss: 0.0141, loss: 0.0144, recall: 0.6797, mrr: 0.6253, time: 0.10013604164123535\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 56\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 75\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 123\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 135\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 255\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 154\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 132\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 56, train loss: 0.0142, loss: 0.0143, recall: 0.7031, mrr: 0.6589, time: 0.10022568702697754\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 81\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 145, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6725, time: 0.0898582935333252\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 117\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 135, train loss: 0.0143, loss: 0.0145, recall: 0.6328, mrr: 0.5501, time: 0.10358881950378418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 255, train loss: 0.0142, loss: 0.0146, recall: 0.6328, mrr: 0.5983, time: 0.06912970542907715\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 109\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 154, train loss: 0.0143, loss: 0.0147, recall: 0.5469, mrr: 0.5172, time: 0.11112809181213379\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 132, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6432, time: 0.10655593872070312\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 81, train loss: 0.0144, loss: 0.0146, recall: 0.5469, mrr: 0.5155, time: 0.1205911636352539\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 117, train loss: 0.0143, loss: 0.0147, recall: 0.6484, mrr: 0.5910, time: 0.10367417335510254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 123, train loss: 0.0144, loss: 0.0145, recall: 0.6641, mrr: 0.5559, time: 0.12350225448608398\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 109, train loss: 0.0144, loss: 0.0146, recall: 0.5898, mrr: 0.5479, time: 0.08930540084838867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 84\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 84, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5408, time: 0.06715106964111328\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 71\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 71, train loss: 0.0143, loss: 0.0146, recall: 0.6354, mrr: 0.5727, time: 0.07934069633483887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 289, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6410, time: 0.07475996017456055\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 9\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 9, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.6510, time: 0.06743764877319336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 199\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 199, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.5859, time: 0.07914996147155762\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 233\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 261\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 62\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 198\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 233, train loss: 0.0144, loss: 0.0146, recall: 0.6875, mrr: 0.6099, time: 0.08375096321105957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 261, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6956, time: 0.0690925121307373\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 198, train loss: 0.0144, loss: 0.0143, recall: 0.6875, mrr: 0.6510, time: 0.07375311851501465\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 62, train loss: 0.0143, loss: 0.0145, recall: 0.6797, mrr: 0.6160, time: 0.07344269752502441\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 78\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 78, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5217, time: 0.08598709106445312\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 92\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 92, train loss: 0.0143, loss: 0.0146, recall: 0.6875, mrr: 0.6057, time: 0.06745696067810059\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 272\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 272, train loss: 0.0143, loss: 0.0143, recall: 0.6667, mrr: 0.6201, time: 0.07726502418518066\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 268\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 87\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 235\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 221\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 232\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 268, train loss: 0.0143, loss: 0.0146, recall: 0.6172, mrr: 0.5504, time: 0.1328258514404297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 87, train loss: 0.0143, loss: 0.0144, recall: 0.6797, mrr: 0.6105, time: 0.1365368366241455\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 158\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 215, train loss: 0.0144, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.11350703239440918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 235, train loss: 0.0143, loss: 0.0146, recall: 0.6146, mrr: 0.5985, time: 0.10516643524169922\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 221, train loss: 0.0143, loss: 0.0144, recall: 0.7135, mrr: 0.6486, time: 0.08004283905029297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 232, train loss: 0.0144, loss: 0.0150, recall: 0.5781, mrr: 0.4168, time: 0.0809776782989502\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 125, train loss: 0.0144, loss: 0.0147, recall: 0.6328, mrr: 0.5630, time: 0.11457371711730957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 158, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6100, time: 0.06253385543823242\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 264\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 90\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 239\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 17\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 182\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 194\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 194, train loss: 0.0144, loss: 0.0144, recall: 0.6484, mrr: 0.5712, time: 0.08155179023742676\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 160\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 160, train loss: 0.0143, loss: 0.0146, recall: 0.6641, mrr: 0.6146, time: 0.09042000770568848\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 264, train loss: 0.0143, loss: 0.0143, recall: 0.7500, mrr: 0.6477, time: 0.09441733360290527\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 90, train loss: 0.0144, loss: 0.0145, recall: 0.6328, mrr: 0.5740, time: 0.0951545238494873\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 96\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 239, train loss: 0.0143, loss: 0.0139, recall: 0.8281, mrr: 0.7766, time: 0.09256577491760254\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 17, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.5509, time: 0.08962011337280273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 182, train loss: 0.0143, loss: 0.0147, recall: 0.6250, mrr: 0.5159, time: 0.07884383201599121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 96, train loss: 0.0142, loss: 0.0148, recall: 0.5938, mrr: 0.5070, time: 0.07694554328918457\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 190\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 162\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 66\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 98\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 190, train loss: 0.0143, loss: 0.0149, recall: 0.5885, mrr: 0.4434, time: 0.12213969230651855\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 162, train loss: 0.0144, loss: 0.0145, recall: 0.5938, mrr: 0.5670, time: 0.08537650108337402\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 66, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5624, time: 0.08229255676269531\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 165\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 165, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6354, time: 0.07001304626464844\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 245\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 179\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 98, train loss: 0.0144, loss: 0.0146, recall: 0.6172, mrr: 0.5344, time: 0.10001111030578613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 245, train loss: 0.0143, loss: 0.0143, recall: 0.6484, mrr: 0.6020, time: 0.1065833568572998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 179, train loss: 0.0143, loss: 0.0146, recall: 0.6719, mrr: 0.6276, time: 0.055269479751586914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 152, train loss: 0.0144, loss: 0.0147, recall: 0.5859, mrr: 0.5428, time: 0.06625032424926758\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 258\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 77\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 140\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 55\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 14\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 113, train loss: 0.0142, loss: 0.0147, recall: 0.6406, mrr: 0.6077, time: 0.0889897346496582\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 258, train loss: 0.0144, loss: 0.0147, recall: 0.5781, mrr: 0.5617, time: 0.09606218338012695\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 77, train loss: 0.0143, loss: 0.0146, recall: 0.6562, mrr: 0.5484, time: 0.09706711769104004\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 140, train loss: 0.0142, loss: 0.0144, recall: 0.6354, mrr: 0.5954, time: 0.11076736450195312\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 55, train loss: 0.0145, loss: 0.0144, recall: 0.6719, mrr: 0.5973, time: 0.11085224151611328\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 14, train loss: 0.0143, loss: 0.0144, recall: 0.6510, mrr: 0.5925, time: 0.07861018180847168\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 107\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 200\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 99\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 116\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 107, train loss: 0.0143, loss: 0.0146, recall: 0.6289, mrr: 0.5212, time: 0.08021426200866699\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 200, train loss: 0.0143, loss: 0.0145, recall: 0.6094, mrr: 0.5898, time: 0.0676887035369873\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 99, train loss: 0.0141, loss: 0.0142, recall: 0.6797, mrr: 0.6686, time: 0.06726574897766113\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 116, train loss: 0.0144, loss: 0.0148, recall: 0.5833, mrr: 0.5042, time: 0.07357478141784668\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 253\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 253, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6102, time: 0.0636599063873291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 250\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 250, train loss: 0.0144, loss: 0.0146, recall: 0.6406, mrr: 0.5544, time: 0.06335973739624023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 207, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6630, time: 0.062497615814208984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 11\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 11, train loss: 0.0145, loss: 0.0146, recall: 0.5703, mrr: 0.5253, time: 0.061151981353759766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 251\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 251, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6435, time: 0.06111264228820801\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 269\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 292\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 121\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 208\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 269, train loss: 0.0142, loss: 0.0142, recall: 0.7031, mrr: 0.6773, time: 0.06812572479248047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 122\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 122, train loss: 0.0142, loss: 0.0145, recall: 0.6719, mrr: 0.6359, time: 0.07468008995056152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 292, train loss: 0.0143, loss: 0.0148, recall: 0.5885, mrr: 0.5603, time: 0.08503961563110352\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 74\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 121, train loss: 0.0144, loss: 0.0142, recall: 0.7500, mrr: 0.7164, time: 0.06468057632446289\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 208, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5952, time: 0.06704068183898926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 74, train loss: 0.0143, loss: 0.0148, recall: 0.5781, mrr: 0.5390, time: 0.08866691589355469\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 161\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 161, train loss: 0.0142, loss: 0.0149, recall: 0.4844, mrr: 0.4410, time: 0.056775569915771484\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 262\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 164\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 108\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 76\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 127\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 32\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 262, train loss: 0.0143, loss: 0.0145, recall: 0.6250, mrr: 0.6031, time: 0.07754063606262207\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 164, train loss: 0.0144, loss: 0.0146, recall: 0.5859, mrr: 0.5257, time: 0.08894968032836914\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 155\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 108, train loss: 0.0143, loss: 0.0145, recall: 0.6302, mrr: 0.5568, time: 0.11717009544372559\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 168\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 127, train loss: 0.0143, loss: 0.0145, recall: 0.6484, mrr: 0.6253, time: 0.08272790908813477\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 32, train loss: 0.0143, loss: 0.0142, recall: 0.7188, mrr: 0.6708, time: 0.1519162654876709\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 133, train loss: 0.0143, loss: 0.0144, recall: 0.7396, mrr: 0.6594, time: 0.10638785362243652\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 155, train loss: 0.0143, loss: 0.0145, recall: 0.6406, mrr: 0.5803, time: 0.10200357437133789\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 168, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5689, time: 0.09203314781188965\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 76, train loss: 0.0144, loss: 0.0147, recall: 0.6146, mrr: 0.5184, time: 0.14798212051391602\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 139\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 52\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 139, train loss: 0.0143, loss: 0.0146, recall: 0.6250, mrr: 0.5710, time: 0.0672612190246582\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 52, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6288, time: 0.05848360061645508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 115\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 115, train loss: 0.0142, loss: 0.0145, recall: 0.6615, mrr: 0.6428, time: 0.06707119941711426\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 178\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 252\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 218\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 178, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6190, time: 0.06308150291442871\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 252, train loss: 0.0144, loss: 0.0142, recall: 0.6797, mrr: 0.6452, time: 0.07945609092712402\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 218, train loss: 0.0142, loss: 0.0143, recall: 0.6979, mrr: 0.6424, time: 0.12774133682250977\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 243\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 299\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 209\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 12\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 12, train loss: 0.0142, loss: 0.0145, recall: 0.6875, mrr: 0.6660, time: 0.06395316123962402\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 243, train loss: 0.0143, loss: 0.0145, recall: 0.7109, mrr: 0.6596, time: 0.07358717918395996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 244\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 134\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 134, train loss: 0.0143, loss: 0.0145, recall: 0.6354, mrr: 0.5526, time: 0.07822775840759277\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 187\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 209, train loss: 0.0144, loss: 0.0144, recall: 0.6953, mrr: 0.6797, time: 0.07863998413085938\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 244, train loss: 0.0142, loss: 0.0144, recall: 0.6458, mrr: 0.5933, time: 0.07134747505187988\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 275\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 196\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 187, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6389, time: 0.07877445220947266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 278\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 275, train loss: 0.0142, loss: 0.0146, recall: 0.6562, mrr: 0.6189, time: 0.07239532470703125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 196, train loss: 0.0144, loss: 0.0145, recall: 0.6458, mrr: 0.6007, time: 0.058007240295410156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 278, train loss: 0.0144, loss: 0.0146, recall: 0.5781, mrr: 0.5431, time: 0.07282710075378418\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 259, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6214, time: 0.06949734687805176"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m   out=out, **kwargs)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m /home/tori/anaconda3/envs/flower3/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m   ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 22\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 22, train loss: 0.0143, loss: 0.0142, recall: 0.6875, mrr: 0.6507, time: 0.06149172782897949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 217\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 217, train loss: 0.0142, loss: 0.0147, recall: 0.6016, mrr: 0.5534, time: 0.059189558029174805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 15\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 15, train loss: 0.0142, loss: 0.0145, recall: 0.6641, mrr: 0.5732, time: 0.06291985511779785\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 120\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 120, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5417, time: 0.05242919921875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 276\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 276, train loss: 0.0144, loss: 0.0146, recall: 0.6302, mrr: 0.5547, time: 0.06626057624816895\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 54\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 106\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 150\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 298\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 54, train loss: 0.0142, loss: 0.0146, recall: 0.6094, mrr: 0.5662, time: 0.0689244270324707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 106, train loss: 0.0142, loss: 0.0149, recall: 0.5625, mrr: 0.4875, time: 0.08643436431884766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 150, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6303, time: 0.11090207099914551\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 298, train loss: 0.0142, loss: 0.0144, recall: 0.7083, mrr: 0.5721, time: 0.10189294815063477\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 185, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.6393, time: 0.06191897392272949\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 257\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 82\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 220\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 257, train loss: 0.0142, loss: 0.0144, recall: 0.7344, mrr: 0.5729, time: 0.07651829719543457\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 60\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 28\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 225\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 25\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 263\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 286\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 142\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 220, train loss: 0.0143, loss: 0.0144, recall: 0.7031, mrr: 0.6339, time: 0.13751769065856934\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 3, train loss: 0.0143, loss: 0.0144, recall: 0.6562, mrr: 0.5861, time: 0.11261725425720215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 60, train loss: 0.0143, loss: 0.0145, recall: 0.5938, mrr: 0.5029, time: 0.1077423095703125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 28, train loss: 0.0143, loss: 0.0143, recall: 0.7344, mrr: 0.7188, time: 0.07837581634521484\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 225, train loss: 0.0143, loss: 0.0142, recall: 0.7266, mrr: 0.6697, time: 0.10998249053955078\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 25, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.6276, time: 0.11305761337280273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 263, train loss: 0.0143, loss: 0.0147, recall: 0.6094, mrr: 0.5726, time: 0.11347079277038574\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 286, train loss: 0.0143, loss: 0.0148, recall: 0.6094, mrr: 0.5820, time: 0.1281757354736328\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 142, train loss: 0.0144, loss: 0.0144, recall: 0.7031, mrr: 0.6676, time: 0.09651017189025879\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 103\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 138\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 31\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 230\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 103, train loss: 0.0143, loss: 0.0145, recall: 0.7188, mrr: 0.5661, time: 0.07078051567077637\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 138, train loss: 0.0143, loss: 0.0144, recall: 0.7344, mrr: 0.6432, time: 0.0631258487701416\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 31, train loss: 0.0143, loss: 0.0141, recall: 0.7188, mrr: 0.6615, time: 0.07490277290344238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 230, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5440, time: 0.06761598587036133\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 53\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 53, train loss: 0.0144, loss: 0.0146, recall: 0.6615, mrr: 0.5601, time: 0.0614466667175293\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 63\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m Start Epoch # 129\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m Start Epoch # 70\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m Start Epoch # 183\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m Start Epoch # 112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m Start Epoch # 266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m Start Epoch # 171\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m Start Epoch # 295\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m Start Epoch # 10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m Start Epoch # 18\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 246\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m Start Epoch # 69\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 42\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m Start Epoch # 88\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m Start Epoch # 64\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m Start Epoch # 79\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318484)\u001b[0m client: 70, train loss: 0.0142, loss: 0.0144, recall: 0.6302, mrr: 0.5645, time: 0.1739661693572998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318491)\u001b[0m client: 183, train loss: 0.0144, loss: 0.0149, recall: 0.5781, mrr: 0.4992, time: 0.16725707054138184\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318496)\u001b[0m client: 171, train loss: 0.0144, loss: 0.0144, recall: 0.6979, mrr: 0.6311, time: 0.17090082168579102\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318489)\u001b[0m client: 10, train loss: 0.0142, loss: 0.0142, recall: 0.7344, mrr: 0.6068, time: 0.17436838150024414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318493)\u001b[0m client: 18, train loss: 0.0143, loss: 0.0146, recall: 0.6302, mrr: 0.5913, time: 0.18713760375976562\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318487)\u001b[0m client: 64, train loss: 0.0144, loss: 0.0145, recall: 0.6562, mrr: 0.5874, time: 0.1768169403076172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318492)\u001b[0m client: 79, train loss: 0.0144, loss: 0.0142, recall: 0.7031, mrr: 0.6241, time: 0.18617630004882812\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 63, train loss: 0.0143, loss: 0.0145, recall: 0.6875, mrr: 0.6448, time: 0.17946171760559082\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318482)\u001b[0m client: 129, train loss: 0.0142, loss: 0.0142, recall: 0.7734, mrr: 0.7216, time: 0.1452796459197998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318486)\u001b[0m client: 112, train loss: 0.0144, loss: 0.0143, recall: 0.6979, mrr: 0.6375, time: 0.1802690029144287\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318483)\u001b[0m client: 266, train loss: 0.0142, loss: 0.0143, recall: 0.7344, mrr: 0.6526, time: 0.18128037452697754\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318494)\u001b[0m client: 295, train loss: 0.0143, loss: 0.0145, recall: 0.6510, mrr: 0.5953, time: 0.18292236328125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 246, train loss: 0.0143, loss: 0.0146, recall: 0.7109, mrr: 0.5932, time: 0.17126941680908203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318490)\u001b[0m client: 69, train loss: 0.0143, loss: 0.0143, recall: 0.6719, mrr: 0.6380, time: 0.17809104919433594\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 42, train loss: 0.0144, loss: 0.0144, recall: 0.6641, mrr: 0.6263, time: 0.14725661277770996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318488)\u001b[0m client: 88, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.5931, time: 0.18382692337036133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 279\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 279, train loss: 0.0141, loss: 0.0146, recall: 0.7422, mrr: 0.6980, time: 0.05710339546203613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m Start Epoch # 1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 35\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 35, train loss: 0.0143, loss: 0.0143, recall: 0.6823, mrr: 0.6280, time: 0.06157565116882324\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 102\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318497)\u001b[0m client: 1, train loss: 0.0143, loss: 0.0143, recall: 0.6797, mrr: 0.5926, time: 0.06122112274169922\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 102, train loss: 0.0144, loss: 0.0145, recall: 0.6615, mrr: 0.6044, time: 0.0612177848815918\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 172\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 172, train loss: 0.0143, loss: 0.0144, recall: 0.6719, mrr: 0.6219, time: 0.051888227462768555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 222, train loss: 0.0143, loss: 0.0144, recall: 0.7500, mrr: 0.6531, time: 0.056932687759399414\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 89\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 89, train loss: 0.0143, loss: 0.0149, recall: 0.5729, mrr: 0.5129, time: 0.05910229682922363\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 181\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 181, train loss: 0.0142, loss: 0.0146, recall: 0.6719, mrr: 0.6237, time: 0.0480809211730957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 186, train loss: 0.0143, loss: 0.0144, recall: 0.6992, mrr: 0.5725, time: 0.06336641311645508\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 65\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 65, train loss: 0.0142, loss: 0.0144, recall: 0.6719, mrr: 0.6094, time: 0.05354666709899902\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 280\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 280, train loss: 0.0143, loss: 0.0145, recall: 0.6641, mrr: 0.6083, time: 0.05612659454345703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 72\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 72, train loss: 0.0143, loss: 0.0148, recall: 0.5938, mrr: 0.5529, time: 0.05728936195373535\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 100\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 283\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 100, train loss: 0.0143, loss: 0.0145, recall: 0.6719, mrr: 0.6320, time: 0.05440068244934082\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 283, train loss: 0.0144, loss: 0.0144, recall: 0.6172, mrr: 0.5931, time: 0.049019813537597656\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 256\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 256, train loss: 0.0143, loss: 0.0145, recall: 0.6562, mrr: 0.6309, time: 0.05203604698181152\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 126\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 126, train loss: 0.0143, loss: 0.0141, recall: 0.7734, mrr: 0.6767, time: 0.05660247802734375\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 8\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 8, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6038, time: 0.058119773864746094\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 7\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 7, train loss: 0.0144, loss: 0.0146, recall: 0.6250, mrr: 0.6038, time: 0.055484771728515625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 260\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 260, train loss: 0.0143, loss: 0.0142, recall: 0.7500, mrr: 0.7233, time: 0.04896116256713867\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 39\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 124\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 124, train loss: 0.0143, loss: 0.0144, recall: 0.7266, mrr: 0.6259, time: 0.053009033203125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 39, train loss: 0.0142, loss: 0.0146, recall: 0.6250, mrr: 0.5569, time: 0.05531454086303711\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 273, train loss: 0.0143, loss: 0.0146, recall: 0.5938, mrr: 0.5653, time: 0.059940338134765625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 37\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 37, train loss: 0.0144, loss: 0.0147, recall: 0.6133, mrr: 0.5169, time: 0.05649542808532715\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 83\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 83, train loss: 0.0143, loss: 0.0148, recall: 0.5625, mrr: 0.4795, time: 0.06321048736572266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 193\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 193, train loss: 0.0144, loss: 0.0145, recall: 0.6042, mrr: 0.5546, time: 0.06069350242614746\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 201\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 95\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 95, train loss: 0.0142, loss: 0.0145, recall: 0.5938, mrr: 0.5624, time: 0.05192279815673828\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 201, train loss: 0.0144, loss: 0.0144, recall: 0.6562, mrr: 0.6167, time: 0.056737661361694336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 33\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 33, train loss: 0.0144, loss: 0.0146, recall: 0.6823, mrr: 0.6515, time: 0.06387972831726074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m Start Epoch # 4\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318485)\u001b[0m client: 4, train loss: 0.0143, loss: 0.0143, recall: 0.6953, mrr: 0.6305, time: 0.056015968322753906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 91\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 91, train loss: 0.0143, loss: 0.0147, recall: 0.6615, mrr: 0.5559, time: 0.06176137924194336\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 291\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 291, train loss: 0.0143, loss: 0.0144, recall: 0.6615, mrr: 0.6156, time: 0.05516242980957031\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 173\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 173, train loss: 0.0142, loss: 0.0148, recall: 0.6562, mrr: 0.5505, time: 0.05355501174926758\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 86\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 86, train loss: 0.0143, loss: 0.0146, recall: 0.5990, mrr: 0.5689, time: 0.061049699783325195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 238\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 238, train loss: 0.0143, loss: 0.0144, recall: 0.6927, mrr: 0.6056, time: 0.052677154541015625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 195\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 195, train loss: 0.0144, loss: 0.0145, recall: 0.7656, mrr: 0.7161, time: 0.04947328567504883\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 285\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 285, train loss: 0.0144, loss: 0.0144, recall: 0.6406, mrr: 0.6250, time: 0.05351901054382324\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 249\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 249, train loss: 0.0144, loss: 0.0148, recall: 0.5859, mrr: 0.5083, time: 0.053440093994140625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 281, train loss: 0.0143, loss: 0.0143, recall: 0.7578, mrr: 0.7477, time: 0.05805253982543945\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 36\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 36, train loss: 0.0143, loss: 0.0144, recall: 0.7422, mrr: 0.6885, time: 0.05660820007324219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 13:46:02,125 | server.py:281 | fit_round received 297 results and 3 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m Start Epoch # 147\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=318495)\u001b[0m client: 147, train loss: 0.0143, loss: 0.0143, recall: 0.6562, mrr: 0.6409, time: 0.0546727180480957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-17 13:46:03,365 | server.py:215 | evaluate_round: strategy sampled 150 clients (out of 300)\n",
      "DEBUG flower 2022-06-17 13:48:02,891 | server.py:227 | evaluate_round received 149 results and 1 failures\n",
      "INFO flower 2022-06-17 13:48:02,892 | server.py:182 | FL finished in 3911.759077187002\n",
      "INFO flower 2022-06-17 13:48:02,894 | app.py:149 | app_fit: losses_distributed [(1, 0.01565447713119567), (2, 0.015653786061830377), (3, 0.01565523891953344), (4, 0.015654583338309897), (5, 0.015654574699045052)]\n",
      "INFO flower 2022-06-17 13:48:02,894 | app.py:150 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-06-17 13:48:02,895 | app.py:151 | app_fit: losses_centralized []\n",
      "INFO flower 2022-06-17 13:48:02,895 | app.py:152 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.01565447713119567\n",
       "\tround 2: 0.015653786061830377\n",
       "\tround 3: 0.01565523891953344\n",
       "\tround 4: 0.015654583338309897\n",
       "\tround 5: 0.015654574699045052"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "        fraction_eval=0.5,  # Sample 50% of available clients for evaluation\n",
    "        min_fit_clients=1,  # Never sample less than 10 clients for training\n",
    "        min_eval_clients=1,  # Never sample less than 5 clients for evaluation\n",
    "        min_available_clients=1,  # Wait until all 10 clients are available\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS+1,\n",
    "    num_rounds=5,\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "81339668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gru-FL-CategoryRecommendation-300.ipynb to html\n",
      "[NbConvertApp] Writing 1123120 bytes to gru-FL-CategoryRecommendation-300.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('jupyter nbconvert --to html gru-FL-CategoryRecommendation-300.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13b37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
